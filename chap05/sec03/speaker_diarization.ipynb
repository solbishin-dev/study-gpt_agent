{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8bba5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyannote.audio\n",
      "  Downloading pyannote_audio-4.0.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting asteroid-filterbanks>=0.4.0 (from pyannote.audio)\n",
      "  Downloading asteroid_filterbanks-0.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting einops>=0.8.1 (from pyannote.audio)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pyannote.audio) (1.1.4)\n",
      "Collecting lightning>=2.4 (from pyannote.audio)\n",
      "  Downloading lightning-2.5.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting matplotlib>=3.10.0 (from pyannote.audio)\n",
      "  Downloading matplotlib-3.10.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pyannote.audio) (1.38.0)\n",
      "Collecting opentelemetry-exporter-otlp>=1.34.0 (from pyannote.audio)\n",
      "  Downloading opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.34.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pyannote.audio) (1.38.0)\n",
      "Collecting pyannote-core>=6.0.1 (from pyannote.audio)\n",
      "  Downloading pyannote_core-6.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pyannote-database>=6.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote_database-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pyannote-metrics>=4.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote_metrics-4.0.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyannote-pipeline>=4.0.0 (from pyannote.audio)\n",
      "  Downloading pyannote_pipeline-4.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyannoteai-sdk>=0.3.0 (from pyannote.audio)\n",
      "  Downloading pyannoteai_sdk-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pytorch-metric-learning>=2.8.1 (from pyannote.audio)\n",
      "  Downloading pytorch_metric_learning-2.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: rich>=13.9.4 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pyannote.audio) (14.2.0)\n",
      "Collecting safetensors>=0.5.2 (from pyannote.audio)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting soundfile>=0.13.1 (from pyannote.audio)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting torch-audiomentations>=0.12.0 (from pyannote.audio)\n",
      "  Downloading torch_audiomentations-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting torch>=2.8.0 (from pyannote.audio)\n",
      "  Using cached torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchaudio>=2.8.0 (from pyannote.audio)\n",
      "  Downloading torchaudio-2.9.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting torchcodec>=0.6.0 (from pyannote.audio)\n",
      "  Downloading torchcodec-0.8.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting torchmetrics>=1.6.1 (from pyannote.audio)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from asteroid-filterbanks>=0.4.0->pyannote.audio) (2.3.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from asteroid-filterbanks>=0.4.0->pyannote.audio) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->pyannote.audio) (0.20.0)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.4->pyannote.audio)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pytorch-lightning (from lightning>=2.4->pyannote.audio)\n",
      "  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.10.0->pyannote.audio)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.10.0->pyannote.audio)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.10.0->pyannote.audio)\n",
      "  Downloading fonttools-4.60.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.10.0->pyannote.audio)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow>=8 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from matplotlib>=3.10.0->pyannote.audio) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib>=3.10.0->pyannote.audio)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from matplotlib>=3.10.0->pyannote.audio) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-api>=1.34.0->pyannote.audio) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.38.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (1.38.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.38.0 (from opentelemetry-exporter-otlp>=1.34.0->pyannote.audio)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (1.76.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (1.38.0)\n",
      "Requirement already satisfied: requests~=2.7 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (2.32.5)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-grpc==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (6.33.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.34.0->pyannote.audio) (0.59b0)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pyannote-core>=6.0.1->pyannote.audio) (2.3.3)\n",
      "Collecting sortedcontainers>=2.4.0 (from pyannote-core>=6.0.1->pyannote.audio)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting scikit-learn>=1.6.1 (from pyannote-metrics>=4.0.0->pyannote.audio)\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.15.1 (from pyannote-metrics>=4.0.0->pyannote.audio)\n",
      "  Using cached scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting optuna>=4.2.0 (from pyannote-pipeline>=4.0.0->pyannote.audio)\n",
      "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from rich>=13.9.4->pyannote.audio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from rich>=13.9.4->pyannote.audio) (2.19.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from soundfile>=0.13.1->pyannote.audio) (2.0.0)\n",
      "Collecting setuptools (from torch>=2.8.0->pyannote.audio)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from torch>=2.8.0->pyannote.audio) (1.14.0)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.8.0->pyannote.audio)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from torch>=2.8.0->pyannote.audio) (3.1.6)\n",
      "Collecting julius<0.3,>=0.2.3 (from torch-audiomentations>=0.12.0->pyannote.audio)\n",
      "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch-pitch-shift>=1.2.2 (from torch-audiomentations>=0.12.0->pyannote.audio)\n",
      "  Downloading torch_pitch_shift-1.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pycparser in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.13.1->pyannote.audio) (2.23)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.28.1->pyannote.audio) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.28.1->pyannote.audio) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.28.1->pyannote.audio) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.28.1->pyannote.audio) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.28.1->pyannote.audio) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.0->pyannote.audio) (3.23.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->pyannote.audio) (0.1.2)\n",
      "Collecting alembic>=1.5.0 (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio)\n",
      "  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting colorlog (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio)\n",
      "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio) (2.0.44)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pandas>=2.2.3->pyannote-core>=6.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from pandas>=2.2.3->pyannote-core>=6.0.1->pyannote.audio) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.10.0->pyannote.audio) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from requests~=2.7->opentelemetry-exporter-otlp-proto-http==1.38.0->opentelemetry-exporter-otlp>=1.34.0->pyannote.audio) (2.3.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.6.1->pyannote-metrics>=4.0.0->pyannote.audio)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.6.1->pyannote-metrics>=4.0.0->pyannote.audio)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.8.0->pyannote.audio) (1.3.0)\n",
      "Collecting primePy>=1.3 (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.12.0->pyannote.audio)\n",
      "  Downloading primePy-1.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from jinja2->torch>=2.8.0->pyannote.audio) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from typer-slim->huggingface-hub>=0.28.1->pyannote.audio) (8.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning>=2.4->pyannote.audio) (1.22.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=4.2.0->pyannote-pipeline>=4.0.0->pyannote.audio)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.28.1->pyannote.audio) (1.3.1)\n",
      "Downloading pyannote_audio-4.0.1-py3-none-any.whl (891 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.5/891.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asteroid_filterbanks-0.4.0-py3-none-any.whl (29 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading lightning-2.5.6-py3-none-any.whl (827 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.7-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp-1.38.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading pyannote_core-6.0.1-py3-none-any.whl (57 kB)\n",
      "Downloading pyannote_database-6.1.0-py3-none-any.whl (53 kB)\n",
      "Downloading pyannote_metrics-4.0.0-py3-none-any.whl (49 kB)\n",
      "Downloading pyannote_pipeline-4.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pyannoteai_sdk-0.3.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading pytorch_metric_learning-2.9.0-py3-none-any.whl (127 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "Downloading torch_audiomentations-0.12.0-py3-none-any.whl (48 kB)\n",
      "Downloading torchaudio-2.9.1-cp312-cp312-macosx_11_0_arm64.whl (808 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.1/808.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchcodec-0.8.1-cp312-cp312-macosx_11_0_arm64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "Using cached scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading torch_pitch_shift-1.2.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading alembic-1.17.2-py3-none-any.whl (248 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading primePy-1.3-py3-none-any.whl (4.0 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: julius\n",
      "  Building wheel for julius (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21966 sha256=479356a9ede15505e34f0f9ca2228b0504c149cdb3b40d08a6dcf7ea31127120\n",
      "  Stored in directory: /Users/solbi/Library/Caches/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
      "Successfully built julius\n",
      "Installing collected packages: sortedcontainers, primePy, torchcodec, threadpoolctl, setuptools, scipy, safetensors, pyparsing, networkx, Mako, kiwisolver, joblib, fonttools, einops, cycler, contourpy, colorlog, torch, soundfile, scikit-learn, pyannoteai-sdk, matplotlib, lightning-utilities, alembic, torchmetrics, torchaudio, pytorch-metric-learning, pyannote-core, optuna, julius, asteroid-filterbanks, torch-pitch-shift, pytorch-lightning, pyannote-database, torch-audiomentations, pyannote-pipeline, pyannote-metrics, opentelemetry-exporter-otlp-proto-http, lightning, opentelemetry-exporter-otlp, pyannote.audio\n",
      "Successfully installed Mako-1.3.10 alembic-1.17.2 asteroid-filterbanks-0.4.0 colorlog-6.10.1 contourpy-1.3.3 cycler-0.12.1 einops-0.8.1 fonttools-4.60.1 joblib-1.5.2 julius-0.2.7 kiwisolver-1.4.9 lightning-2.5.6 lightning-utilities-0.15.2 matplotlib-3.10.7 networkx-3.5 opentelemetry-exporter-otlp-1.38.0 opentelemetry-exporter-otlp-proto-http-1.38.0 optuna-4.6.0 primePy-1.3 pyannote-core-6.0.1 pyannote-database-6.1.0 pyannote-metrics-4.0.0 pyannote-pipeline-4.0.0 pyannote.audio-4.0.1 pyannoteai-sdk-0.3.0 pyparsing-3.2.5 pytorch-lightning-2.5.6 pytorch-metric-learning-2.9.0 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.3 setuptools-80.9.0 sortedcontainers-2.4.0 soundfile-0.13.1 threadpoolctl-3.6.0 torch-2.9.1 torch-audiomentations-0.12.0 torch-pitch-shift-1.2.5 torchaudio-2.9.1 torchcodec-0.8.1 torchmetrics-1.8.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy==1.26\n",
      "  Downloading numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (53 kB)\n",
      "Downloading numpy-1.26.0-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.4\n",
      "    Uninstalling numpy-2.3.4:\n",
      "      Successfully uninstalled numpy-2.3.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyannote-core 6.0.1 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n",
      "pyannote-metrics 4.0.0 requires numpy>=2.2.2, but you have numpy 1.26.0 which is incompatible.\n",
      "langchain-community 0.4.1 requires numpy>=1.26.2; python_version < \"3.13\", but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyannote.audio\n",
    "%pip install numpy==1.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dbdcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc34888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "/Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/pyannote/audio/core/io.py:47: UserWarning: \n",
      "torchcodec is not installed correctly so built-in audio decoding will fail. Solutions are:\n",
      "* use audio preloaded in-memory as a {'waveform': (channel, time) torch.Tensor, 'sample_rate': int} dictionary;\n",
      "* fix torchcodec installation. Error message was:\n",
      "\n",
      "Could not load libtorchcodec. Likely causes:\n",
      "          1. FFmpeg is not properly installed in your environment. We support\n",
      "             versions 4, 5, 6, and 7 on all platforms, and 8 on Mac and Linux.\n",
      "          2. The PyTorch version (2.9.1) is not compatible with\n",
      "             this version of TorchCodec. Refer to the version compatibility\n",
      "             table:\n",
      "             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n",
      "          3. Another runtime dependency; see exceptions below.\n",
      "        The following exceptions were raised as we tried to load libtorchcodec:\n",
      "        \n",
      "[start of libtorchcodec loading traceback]\n",
      "FFmpeg version 8: Could not load this library: /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/torchcodec/libtorchcodec_core8.dylib\n",
      "FFmpeg version 7: Could not load this library: /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/torchcodec/libtorchcodec_core7.dylib\n",
      "FFmpeg version 6: Could not load this library: /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/torchcodec/libtorchcodec_core6.dylib\n",
      "FFmpeg version 5: Could not load this library: /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/torchcodec/libtorchcodec_core5.dylib\n",
      "FFmpeg version 4: Could not load this library: /Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/torchcodec/libtorchcodec_core4.dylib\n",
      "[end of libtorchcodec loading traceback].\n",
      "  warnings.warn(\n",
      "/Users/solbi/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Pipeline.from_pretrained() got an unexpected keyword argument 'use_auth_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# instantiate the pipeline\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyannote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pipeline = \u001b[43mPipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyannote/speaker-diarization-3.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m  \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHUGGING_FACE_TOKEN\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Pipeline.from_pretrained() got an unexpected keyword argument 'use_auth_token'"
     ]
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=HUGGING_FACE_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241fdf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is not available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# cuda가 사용 가능한 경우 cuda를 사용하도록 설정\n",
    "if torch.cuda.is_available():\n",
    "    pipeline.to(torch.device(\"cuda\"))\n",
    "    print('cuda is available')\n",
    "else:\n",
    "    print('cuda is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec193dab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# run the pipeline on an audio file\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# diarization = pipeline(\"audio.wav\")\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m diarization = \u001b[43mpipeline\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m../audio/싼기타_비싼기타.mp3\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# dump the diarization output to disk using RTTM format\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m싼기타_비싼기타.rttm\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m rttm:\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# run the pipeline on an audio file\n",
    "# diarization = pipeline(\"audio.wav\")\n",
    "diarization = pipeline(\"../audio/싼기타_비싼기타.mp3\")\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"싼기타_비싼기타.rttm\", \"w\", encoding='utf-8') as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58a144c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './싼기타_비싼기타.rttm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m rttm_path = \u001b[33m\"\u001b[39m\u001b[33m./싼기타_비싼기타.rttm\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_rttm = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrttm_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# rttm 파일 경로\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 구분자는 띄어쓰기\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 헤더는 없음\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfile\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mchnl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstart\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mduration\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspeaker_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mC4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m display(df_rttm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/study-gpt_agent/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './싼기타_비싼기타.rttm'"
     ]
    }
   ],
   "source": [
    "# RTTM을 CSV로 변환\n",
    "import pandas as pd\n",
    "rttm_path = \"./싼기타_비싼기타.rttm\"\n",
    "\n",
    "df_rttm = pd.read_csv(\n",
    "    rttm_path,      # rttm 파일 경로\n",
    "    sep=' ',        # 구분자는 띄어쓰기\n",
    "    header=None,    # 헤더는 없음\n",
    "    names=['type', 'file', 'chnl', 'start', 'duration', 'C1', 'C2', 'speaker_id', 'C3', 'C4'] \n",
    ")\n",
    "\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29fad16",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_rttm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# start + duration을 end로 변환\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_rttm[\u001b[33m'\u001b[39m\u001b[33mend\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_rttm\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m'\u001b[39m] + df_rttm[\u001b[33m'\u001b[39m\u001b[33mduration\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m display(df_rttm)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_rttm' is not defined"
     ]
    }
   ],
   "source": [
    "# start + duration을 end로 변환\n",
    "df_rttm['end'] = df_rttm['start'] + df_rttm['duration']\n",
    "\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae5f7e74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_rttm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_rttm\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\t\u001b[38;5;66;03m# number 열 만들고 None으로 초기화\u001b[39;00m\n\u001b[32m      2\u001b[39m df_rttm.at[\u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m      4\u001b[39m display(df_rttm)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_rttm' is not defined"
     ]
    }
   ],
   "source": [
    "df_rttm[\"number\"] = None\t# number 열 만들고 None으로 초기화\n",
    "df_rttm.at[0, \"number\"] = 0\n",
    "\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4cb41e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_rttm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf_rttm\u001b[49m)):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m df_rttm.at[i, \u001b[33m\"\u001b[39m\u001b[33mspeaker_id\u001b[39m\u001b[33m\"\u001b[39m] != df_rttm.at[i-\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mspeaker_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      3\u001b[39m         df_rttm.at[i, \u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m] = df_rttm.at[i-\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_rttm' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(df_rttm)):\n",
    "    if df_rttm.at[i, \"speaker_id\"] != df_rttm.at[i-1, \"speaker_id\"]:\n",
    "        df_rttm.at[i, \"number\"] = df_rttm.at[i-1, \"number\"] + 1\n",
    "    else:\n",
    "        df_rttm.at[i, \"number\"] = df_rttm.at[i-1, \"number\"]\n",
    "\n",
    "display(df_rttm.head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea16774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped = df_rttm.groupby(\"number\").agg(\n",
    "    start=pd.NamedAgg(column='start', aggfunc='min'),\n",
    "    end=pd.NamedAgg(column='end', aggfunc='max'),\n",
    "    speaker_id=pd.NamedAgg(column='speaker_id', aggfunc='first')\n",
    ")\n",
    "\n",
    "display(df_rttm_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35700fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped[\"duration\"] = df_rttm_grouped[\"end\"] - df_rttm_grouped[\"start\"]\n",
    "df_rttm_grouped = df_rttm_grouped.reset_index(drop=True)\n",
    "display(df_rttm_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d3da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped.to_csv(\n",
    "    \"싼기타_비싼기타_rttm.csv\",\n",
    "    sep=',',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
