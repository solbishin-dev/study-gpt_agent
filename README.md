### Do it! LLMì„ í™œìš©í•œ AIì—ì´ì „íŠ¸ ê°œë°œ ì…ë¬¸ ì±… ë³´ê³  ê³µë¶€í•œ ë‚´ìš©ì„ ê¸°ë¡í•©ë‹ˆë‹¤.

<img width="458" height="626" alt="image" src="https://github.com/user-attachments/assets/5402108c-45a6-428a-999d-cec95ace52b8" />


### 1ì¥ LLMìœ¼ë¡œ ì–´ë–¤ ì¼ì„ í•  ìˆ˜ ìˆì„ê¹Œ?

### 01-1 ì±—GPTë¡œ ì‹œì‘ëœ ìƒì„±í˜• AIì‹œëŒ€

LLMì€ ë¬´ì—‡ì¼ê¹Œ?

- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM): ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„± (ex. GPT, ì œë¯¸ë‚˜ì´, í´ë¡œë“œ, ë¼ë§ˆ ..ë“±)

GPT, ì±— GPTì˜ ì°¨ì´

- GPT: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ê·¸ ìì²´
- ì±—GPT: GPTë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•„ìš”í•œ ê¸°ëŠ¥ì„ ë§ë¶™ì—¬ ì œê³µí•˜ëŠ” ì±„íŒ… í˜•íƒœ ì„œë¹„ìŠ¤

LLMì˜ ì¢…ë¥˜

- GPT: ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë¡œ ë°œì „
- ì œë¯¸ë‚˜ì´
- ë¼ë§ˆ
- í´ë¡œë“œ
- ë”¥ì‹œí¬

LLMì„ í™œìš©í•œ ìƒì„±í˜• AIì„œë¹„ìŠ¤ì˜ ì¢…ë¥˜

- ì±—GPT
- í¼í”Œë ‰ì‹œí‹°
- SKT ì—ì´ë‹·: í†µí™” ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
ì˜¨ë¼ì¸ ë¯¸íŒ… íšŒì˜ë¡ ìë™ ì‘ì„± í›„ ìš”ì•½ë³¸ ì´ë©”ì¼ë¡œ ì „ì†¡ ì„œë¹„ìŠ¤
- AI Companion: ì¤Œì—ì„œ ê°œë°œ
- Knoxë¯¸íŒ…: ì‚¼ì„± SDS
- ì¸í”„ëŸ° AI ì¸í„´: ê°•ì˜ ì§ˆë¬¸ì— ë‹µë³€

### 01-2 LLMì„ ì™œ ê³µë¶€í•´ì•¼ í• ê¹Œ?

LLM í”„ë¡œê·¸ë˜ë° ê²½í—˜ì´ í•„ìš”í•œ ì´ìœ  

ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•´ ì—…ë¬´ ìë™í™”, ì±—ë´‡ ë§Œë“œëŠ” ê³¼ì •ì„ ì§ì ‘ í•˜ë©´ì„œ ìƒì„±í˜• AIì™€ ì–¸ì–´ ëª¨ë¸ì˜ ì¥ì ê³¼ í•œê³„ ì´í•´í•˜ê³  ì´ë¥¼ í†µí•´ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ ê¸°ìˆ ì„ ì•Œì•„ë³´ê³  ì¡°í•©í•´ì„œ ì²´ê³„í™”

ì–´ë–¤ ì–¸ì–´ ëª¨ë¸ì„ ì„ íƒí•´ì•¼í• ê¹Œ?
í˜„ì¬ GPT ì–¸ì–´  ëª¨ë¸ì„ ê°€ì¥ ë§ì´ ì‚¬ìš©

ë³´ì•ˆ, ë¹„ìš©ì„ ê³ ë ¤í•˜ë©´ ì†Œê·œëª¨ ì–¸ì–´ ëª¨ë¸(SLM) ê³ ë ¤ 

LLMì˜ í•œê³„ë¥¼ ë³´ì™„í•˜ëŠ” ê¸°ìˆ  6ê°€ì§€

- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§: ì–¸ì–´ ëª¨ë¸ì˜ ë‹µë³€ì„ ìµœì í™”í•˜ê¸° ìœ„í•´ ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„
- íŒŒì¸ íŠœë‹: ì´ë¯¸ í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì— ì›í•˜ëŠ” ë¶„ì•¼ë‚˜ íŠ¹ì • ìš©ë„ì— ë§ê²Œ ì¶”ê°€ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê¸°ë²•, ì¼ë°˜ PCì—ì„œ êµ¬ë™x, ëŒ€ë¶€ë¶„ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ê³¼ RAGë¥¼ ì´ìš©í•´ ê°œì„ 
- RAG: í•„ìš”í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì„œ ë‹µë³€í•  ë•Œ í™œìš©í•˜ë„ë¡ ë•ëŠ” ê¸°ìˆ 
- í‘ì…˜ ì½œë§ê³¼ ë„êµ¬ í˜¸ì¶œ: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì´ ë‹¨ìˆœ ë‹µë³€ì— ê·¸ì¹˜ì§€ ì•Šê³  ì™¸ë¶€APIë‚˜ ì§ì ‘ ë§Œë“  í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ê·¸ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ìˆ 
- ë­ì²´ì¸: ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ëŠ” í”„ë ˆì„ì›Œí¬
- ë­ê·¸ë˜í”„: ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ì–´ í˜‘ì—…í•˜ë„ë¡ ì‹œìŠ¤í…œì„ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì¸ ë©€í‹° ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•˜ëŠ” í”„ë ˆì„ ì›Œí¬ ì¤‘ í•˜ë‚˜

### 2ì¥ í™˜ê²½ ì„¤ì •í•˜ê³  GPT API ì‹œì‘í•˜ê¸°

ì˜¤í”ˆAIì˜ API í‚¤ë¡œ ì§ˆë¬¸í•˜ê³  ë‹µë³€ ë°›ê¸°

```jsx
pip install openai==1.58.1 // pip install open aië„ OK
```

- ë„·í”Œë¦­ìŠ¤ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì˜í™”/ë“œë¼ë§ˆ top10ì„ ì•Œë ¤ì¤˜

```jsx
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

response = client.chat.completions.create(
  model="gpt-4o",
  temperature=0.1,
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "ë„·í”Œë¦­ìŠ¤ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì˜í™”/ë“œë¼ë§ˆ top10ì„ ì•Œë ¤ì¤˜"},
  ]
)

print(response)
print('------')
print(response.choices[0].message.content)

```

```jsx
í˜„ì¬ ì‹œì ì—ì„œ ë„·í”Œë¦­ìŠ¤ì˜ ì¸ê¸° ì½˜í…ì¸ ëŠ” ì§€ì—­ê³¼ ì‹œê°„ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
ë„·í”Œë¦­ìŠ¤ëŠ” ì •ê¸°ì ìœ¼ë¡œ ì¸ê¸° ìˆëŠ” ì˜í™”ì™€ ë“œë¼ë§ˆì˜ ìˆœìœ„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. 
ê°€ì¥ ì •í™•í•œ ì •ë³´ë¥¼ ì–»ìœ¼ë ¤ë©´ ë„·í”Œë¦­ìŠ¤ ì•±ì´ë‚˜ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì—¬ "Top 10" ì„¹ì…˜ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.    
ì¼ë°˜ì ìœ¼ë¡œ ë„·í”Œë¦­ìŠ¤ì˜ ì¸ê¸° ì½˜í…ì¸ ëŠ” ìƒˆë¡œìš´ ì˜¤ë¦¬ì§€ë„ ì‹œë¦¬ì¦ˆ, í™”ì œì˜ ì˜í™”, ê·¸ë¦¬ê³  ìµœê·¼ì— ì¶”ê°€ëœ ì¸ê¸° ìˆëŠ” ì‘í’ˆë“¤ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. 
íŠ¹ì • ì‹œì ì˜ ì¸ê¸° ì½˜í…ì¸ ë¥¼ ì•Œê³  ì‹¶ë‹¤ë©´ ë„·í”Œë¦­ìŠ¤ì˜ ê³µì‹ ë°œí‘œë‚˜ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¸ê³ í•˜ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.
```

- (ë²”ìœ„ ì¢íˆê¸°) 2025ë…„ 10ì›”, í•œêµ­ì—ì„œ ê°€ì¥ í‰ì ì´ ë†’ì€ ì˜í™”, ë“œë¼ë§ˆ top10ì„ ì•Œë ¤ì¤˜

```jsx
ì£„ì†¡í•˜ì§€ë§Œ, 2025ë…„ 10ì›”ì˜ ë°ì´í„°ëŠ” í˜„ì¬ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
ì œ ë°ì´í„°ëŠ” 2023ë…„ 10ì›”ê¹Œì§€ì˜ ì •ë³´ë¡œ ì œí•œë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
ê·¸ëŸ¬ë‚˜ í•œêµ­ì—ì„œ ì¸ê¸° ìˆëŠ” ì˜í™”ì™€ ë“œë¼ë§ˆë¥¼ ì°¾ìœ¼ì‹œë ¤ë©´, ë„¤ì´ë²„ ì˜í™”, ë‹¤ìŒ ì˜í™”, ë˜ëŠ” ë„·í”Œë¦­ìŠ¤, ì™“ì± ì™€ ê°™ì€ 
ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì˜ ìµœì‹  ìˆœìœ„ë¥¼ ì°¸ê³  í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. 
ì´ëŸ¬í•œ í”Œë«í¼ë“¤ì€ ì‚¬ìš©ì ë¦¬ë·°ì™€ í‰ì ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì‹  ì¸ê¸° ì½˜í…ì¸ ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
```

ê´œíˆ ë¬¼ì–´ë´¤ë”°â€¦ 2023ë…„ 10ì›”ê¹Œì§€ ì •ë³´ë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì–´ì„œ ìµœì‹  ì •ë³´ë¥¼ ë¬¼ì–´ë³´ëŠ” ê±´ í•œê³„ê°€ ìˆìŒ!

### 3ì¥ ì˜¤í”ˆAIì˜ APIë¡œ ì±—ë´‡ ë§Œë“¤ê¸°

03-1 í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì•Œì•„ë³´ê¸°

- ì›ìƒ· í”„ë¡¬í”„íŒ…: GPTê°€ ì›í•˜ëŠ” íŒ¨í„´ì— ë§ì¶° ë‹µë³€í•˜ë„ë¡ ì˜ˆì‹œë¥¼ í•œë²ˆ ì œì‹œí•´ì„œ ìœ ë„í•˜ëŠ” ë°©ì‹
- í“¨ì‚¿ í”„ë¡¬í”„íŒ…: ì˜ˆì‹œë¥¼ ì—¬ëŸ¬ ë²ˆ ì•Œë ¤ ì£¼ëŠ” ë°©ì‹

- no prompting

```jsx
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=api_key)
 
response = client.chat.completions.create(
  model="gpt-4o",
  temperature=0.9, 
  messages=[
    {"role": "system", "content": "ë„ˆëŠ” ìœ ì¹˜ì› í•™ìƒì´ì•¼. ìœ ì¹˜ì›ìƒì²˜ëŸ¼ ë‹µë³€í•´ì¤˜."},
    {"role": "user", "content": "ì˜¤ë¦¬"},
  ]	
)
print(response.choices[0].message.content) 

// ê½¥ê½¥! ì˜¤ë¦¬ ì¬ë°Œì–´! ì˜¤ë¦¬ëŠ” ë¬¼ì—ì„œ í—¤ì—„ì¹˜ê³  ê½¥ê½¥ ì†Œë¦¬ ë‚´ëŠ” ê·€ì—¬ìš´ ë™ë¬¼ì´ì•¼! ë„ˆ ì˜¤ë¦¬ ì¢‹ì•„í•´? ğŸ¦†
```

- one shot prompt

```jsx
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=api_key)

response = client.chat.completions.create(
  model="gpt-4o",
  temperature=0.9,
  messages=[
    {"role": "system", "content": "ë„ˆëŠ” ìœ ì¹˜ì› í•™ìƒì´ì•¼. ìœ ì¹˜ì›ìƒì²˜ëŸ¼ ë‹µë³€í•´ì¤˜."},
    {"role": "user", "content": "ì°¸ìƒˆ"},
    {"role": "assistant", "content": "ì§¹ì§¹"},
    {"role": "user", "content": "ì˜¤ë¦¬"},
  ]		
)

print(response.choices[0].message.content) 

// ê½¥ê½¥!
```

- ê°•ì•„ì§€: ë©ë©! ê·€ì—¬ì›Œ!
- ì—¬ìš°: ì—¬ìš°ëŠ” ê¼¬ë¦¬ê°€ ê¸¸ê³  ë˜‘ë˜‘í•´! ìƒ‰ê¹”ì€ ì£¼í™©ìƒ‰ì´ì—ìš”, ê·¼ë° í•˜ì–€ ì—¬ìš°ë„ ìˆì–´ìš”! ğŸ¦Š
- ì†Œ: ìŒë©”! ì†ŒëŠ” ìš°ìœ  ì¤˜! ë§›ìˆì–´!
- ë™ë¬¼ì´ ì•„ë‹Œ ê±¸ ì…ë ¥í–ˆì„ ë•Œ
    - ë„ê¹¨ë¹„: ë„ê¹¨ë¹„ëŠ” ë¬´ì„œìš´ ê±° ë§ê³  ì°©í•œ ê²ƒë„ ìˆì–´! ë„ê¹¨ë¹„ ë°©ë§ì´ë¡œ ë‘ë“¤ê¸°ë©´ ë–¡ì´ ë‚˜ì˜¨ë‹¤ê³  í•´! ì¬ë°Œì§€?
- few shot prompt

```jsx
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key=api_key)
 
response = client.chat.completions.create(
  model="gpt-4o",
  temperature=0.9, 
  messages=[
    {"role": "system", "content": "ë„ˆëŠ” ìœ ì¹˜ì› í•™ìƒì´ì•¼. ìœ ì¹˜ì›ìƒì²˜ëŸ¼ ë‹µë³€í•´ì¤˜."},
    {"role": "user", "content": "ì°¸ìƒˆ"},
    {"role": "assistant", "content": "ì§¹ì§¹"},
    {"role": "user", "content": "ë§"},
    {"role": "assistant", "content": "íˆì´ì‰"},
    {"role": "user", "content": "ê°œêµ¬ë¦¬"},
    {"role": "assistant", "content": "ê°œêµ´ê°œêµ´"},
    {"role": "user", "content": "ë±€"},
  ]		
)
print(response.choices[0].message.content) 

//ìŠ¤ë¥´ë¥´ë¥´~
```

- ëŠ‘ëŒ€: ì•„ìš°ìš°~~!
- ë‹­: ê¼¬ë¼ì˜¤! ğŸ”
- ë¹„ë‘˜ê¸°: êµ¬êµ¬! êµ¬êµ¬!

03-2 GPTì™€ ë©€í‹°í„´ ëŒ€í™”í•˜ê¸°

- ë©€í‹°í„´: ì—¬ëŸ¬ ë²ˆ ëŒ€í™”(í„´)í•  ë•Œ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  ì ì ˆí•˜ê²Œ ë°˜ì‘í•˜ëŠ” ê²ƒ
- ê³¼ê±° ëŒ€í™” ë‚´ìš©ì„ ê¸°ì–µ ëª»í•˜ëŠ” GPT

```jsx
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°

client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

while True:
    user_input = input("ì‚¬ìš©ì: ")

    if user_input == "exit":
        break

    response = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.9,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},
            {"role": "user", "content": user_input},
        ],
    )
    print("AI: " + response.choices[0].message.content)

```

```jsx
ì‚¬ìš©ì: ì•ˆë…•? ë‚´ ì´ë¦„ì€ ë¹„ë¹„ì´ê³  ë‚˜ì´ëŠ” 33ì‚´ì´ì•¼
AI: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ë¹„ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?
ì‚¬ìš©ì: ë‚´ ì´ë¦„ì´ ë­ê²Œ?
AI: ë‹¹ì‹ ì˜ ì´ë¦„ì„ ëª¨ë¥´ì§€ë§Œ, ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ì§ˆë¬¸ì´ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!
ì‚¬ìš©ì: ë‚´ ë‚˜ì´ê°€ ëª‡ì‚´ì´ê²Œ?
AI: ë‹¹ì‹ ì˜ ë‚˜ì´ë¥¼ ì¶”ì¸¡í•˜ê¸° ìœ„í•´ì„œëŠ” ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ìƒë…„ì›”ì¼ì´ë‚˜ ë‚˜ì´ì— ëŒ€í•œ íŒíŠ¸ë¥¼ ì£¼ì‹œë©´ ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.
ì‚¬ìš©ì: exit
```

- ë©€í‹°í„´ ëŒ€í™” ë§Œë“¤ê¸°

```jsx
from openai import OpenAI  # ì˜¤í”ˆAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê¸°
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°

client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

def get_ai_response(messages):
    response = client.chat.completions.create(
        model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
        temperature=0.9,  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  temperature ì„¤ì •
        messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
    )
    return response.choices[0].message.content  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš© ë°˜í™˜

messages = [
    {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
]

while True:
    user_input = input("ì‚¬ìš©ì: ")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°

    if user_input == "exit":  # ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ëŠ”ì§€ í™•ì¸ì¸
        break
    
    messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€ 
    ai_response = get_ai_response(messages)  # ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ AI ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
    messages.append({"role": "assistant", "content": ai_response})  # AI ì‘ë‹µ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê¸°

    print("AI: " + ai_response)  # AI ì‘ë‹µ ì¶œë ¥

```

```jsx
ì‚¬ìš©ì: ì•ˆë…•? ë‚´ ì´ë¦„ì€ ë¹„ë¹„ì•¼. ë‚˜ì´ëŠ” 33ì‚´ì´ì•¼
AI: ì•ˆë…•í•˜ì„¸ìš”, ë¹„ë¹„ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?
ì‚¬ìš©ì: ë‚´ê°€ ëˆ„êµ¬ê²Œ?
AI: ë¹„ë¹„ë‹˜ì— ëŒ€í•´ ì•„ì§ ì•„ëŠ” ê²ƒì´ ë§ì§€ ì•Šì§€ë§Œ, 33ì‚´ì´ë¼ëŠ” ì •ë³´ì™€ ë°ê³  ì¹œê·¼í•œ ì¸ìƒì„ ì£¼ì‹œëŠ” ê²ƒ ê°™ì•„ìš”. í˜¹ì‹œ íŠ¹ë³„íˆ ê¶ê¸ˆí•œ ê²ƒì´ë‚˜ í•¨ê»˜ ë‚˜ëˆ„ê³  ì‹¶ì€ ì´ì•¼ê¸°ê°€ ìˆì„ê¹Œìš”?
ì‚¬ìš©ì: ë¯¸êµ­ì—ì„œ ì œì¼ ì¸ê¸°ìˆëŠ” ì—°ì˜ˆì¸ì€ ëˆ„êµ¬ì•¼?
AI: ë¯¸êµ­ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ì—°ì˜ˆì¸ì€ ì‹œê¸°ì™€ ê¸°ì¤€ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì§€ë§Œ, ëª‡ëª‡ ì´ë¦„ì€ ìì£¼ ê±°ë¡ ë˜ê³¤ í•´ìš”. ì˜ˆë¥¼ ë“¤ì–´, ê°€ìˆ˜ì¸ í…Œì¼ëŸ¬ ìŠ¤ìœ„í”„íŠ¸ì™€ ë¹„ìš˜ì„¸, ë°°ìš°ì¸ ë“œì›¨ì¸ ì¡´ìŠ¨ê³¼ ë ˆì˜¤ë‚˜ë¥´ë„ ë””ì¹´í”„ë¦¬ì˜¤ ë“±ì€ ê¾¸ì¤€íˆ ë†’ì€ ì¸ê¸°ë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë“¤ì˜ ì‘í’ˆ, ê³µë¡œ, ê·¸ë¦¬ê³  ì‚¬íšŒì  ì˜í–¥ë ¥ì´ ì´ëŸ¬í•œ ì¸ê¸°ë¥¼ ë’·ë°›ì¹¨í•˜ì£ . ê´€ì‹¬ ìˆëŠ” íŠ¹ì • ë¶„ì•¼ë‚˜ ìµœê·¼ íŠ¸ë Œë“œë¥¼ ë§ì”€í•´ì£¼ì‹œë©´ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!
ì‚¬ìš©ì: í•œêµ­ì—ì„œëŠ”?     
AI: í•œêµ­ì—ì„œëŠ” K-popê³¼ K-ë“œë¼ë§ˆì˜ ì˜í–¥ìœ¼ë¡œ ë§ì€ ì—°ì˜ˆì¸ë“¤ì´ í° ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤. K-popì—ì„œëŠ” ë°©íƒ„ì†Œë…„ë‹¨(BTS), ë¸”ë™í•‘í¬, ê·¸ë¦¬ê³  ì•„ì´ìœ  ê°™ì€ ì•„í‹°ìŠ¤íŠ¸ë“¤ì´ ì„¸ê³„ì ìœ¼ë¡œ í° ì¸ê¸°ë¥¼ ëŒê³  ìˆì£ . ë“œë¼ë§ˆë‚˜ ì˜í™” ë¶„ì•¼ì—ì„œëŠ” ë°°ìš° ì´ë³‘í—Œ, ì†¡ì¤‘ê¸°,  ì „ì§€í˜„, ê·¸ë¦¬ê³  ê¹€ìˆ˜í˜„ ë“±ì´ ê¾¸ì¤€íˆ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ ì—°ì˜ˆê³„ëŠ” ë³€í™”ê°€ ë¹ ë¥´ê³  ë‹¤ì–‘í•œ ì¬ëŠ¥ ìˆëŠ” ì‚¬ëŒë“¤ì´ ê³„ì†í•´ì„œ  ì£¼ëª©ë°›ê³  ìˆì–´ì„œ, íŠ¹ì • ì‹œê¸°ì— ë”°ë¼ ì¸ê¸° ìˆëŠ” ì¸ë¬¼ë“¤ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆì–´ìš”.
```

03-3 ìŠ¤íŠ¸ë¦¼ë¦¿ìœ¼ë¡œ ì±—ë´‡ ì™„ì„±í•˜ê¸°

<img width="1491" height="1363" alt="image" src="https://github.com/user-attachments/assets/5c80603d-3f86-421b-a328-d77552c9c2ef" />

### 4ì¥ ë¬¸ì„œì™€ ë…¼ë¬¸ì„ ìš”ì•½í•˜ëŠ” AI ì—°êµ¬ì›

### 5ì¥ íšŒì˜ë¡ì„ ì •ë¦¬í•˜ëŠ” AI ì„œê¸°
05-1 ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸°

- STT(Speech-To-Text): ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ 
- TTS(Text-To-Speech): STTì™€ ë°˜ëŒ€ë˜ëŠ” ê¸°ìˆ , í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•´ì„œ ì¶œë ¥í•˜ëŠ” ê¸°ìˆ 
- ìœ„ìŠ¤í¼ API í™œìš©í•˜ê¸°
    - MP3ì˜ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

```jsx
Transcription(text='ì•ˆë…•í•˜ì„¸ìš”. ì´ ê°•ì˜ëŠ” GPT APIë¡œ ì±—ë´‡ ë§Œë“¤ê¸°ë¼ëŠ” ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ê°•ì˜ì…ë‹ˆë‹¤.
 GPT APIì— ëŒ€í•´ì„œ ìƒì†Œí•˜ì‹  ë¶„ë“¤ë„ ìˆì„ í…ë° ìš°ë¦¬ê°€ ì˜ ì•Œê³  ìˆëŠ” 
 ì±„GPT, ì±„GPT ê¸°ëŠ¥ì„ ì´ìš©í•´ì„œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ì–´ë–»ê²Œ ë§Œë“œëŠ”ì§€ì— ëŒ€í•´ì„œ ì´ì•¼ê¸°í•  ê±°ì˜ˆìš”. 
 ê·¸ë˜ì„œ ë­ ì´ëŸ° ê°•ì˜ë“¤ì´ ì‚¬ì‹¤ ë§ì´ ìˆìŠµë‹ˆë‹¤. 
 ê·¸ë˜ì„œ ì—¬ëŸ¬ ê°€ì§€ë“¤ì´ ìˆëŠ”ë° ì¢€ ì´ ê°•ì˜ì˜ íŠ¹ì§•ì´ë¼ê³  í•œë‹¤ë©´ GPTë¡œ ëª…í™•í•œ ë¯¸ì…˜ì„ ë‹¬ì„±í•˜ëŠ” ì±—ë´‡ í”„ë¡œê·¸ë¨ì„
  ë§Œë“œëŠ” ê²Œ ì‚¬ì‹¤ ì‰½ì§€ëŠ” ì•Šì€ë° ì´ê±¸ ì–´ë–»ê²Œ í•´ì„œ êµ¬í˜„ì„ í•˜ëŠ”ì§€ ê·¸ë¦¬ê³  ê·¸ê²Œ ì™œ í•„ìš”í•œì§€ì— ëŒ€í•´ì„œ 
  ì¢€ ì´ì•¼ê¸°ë¥¼ í•  ê±°ê³ ìš”. ê·¸ ì˜ˆì œë¡œ ì˜ˆì œëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ë  ìˆ˜ ìˆëŠ”ë° ì—¬ê¸°ì„œ ì˜ˆì œë¡œ í•˜ëŠ” ê²ƒì€
   ìŒì•… í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë™ì˜ìƒì„ ìë™ìœ¼ë¡œ ëŒ€í™”ë¥¼ í†µí•´ì„œ ìƒì„±í•˜ëŠ” í”„ë¡œê·¸ë¨ ë§Œë“œëŠ” ê²ƒì„ ë‹¤ë£¨ë ¤ê³  í•©ë‹ˆë‹¤. 
   ê·¸ë˜ì„œ í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ë˜ëŠ” ëª¨ìŠµì„ í•œë²ˆ ë³´ì—¬ë“œë¦´ê²Œìš”. ìš°ë¦¬ê°€ ë§Œë“¤ í”„ë¡œê·¸ë¨ì€ ì´ëŸ° ì‹ìœ¼ë¡œ ì´ì œ ë‚˜íƒ€ë‚˜ê²Œ
    ë˜ê³ ', logprobs=None, usage=UsageDuration(seconds=58.0, type='duration'))
```

   ì±—GPTê°€ ì±„GPTë¡œ ì¶œë ¥ë¨ 

- ìœ„ìŠ¤í¼ APIë¡œ í•œêµ­ì–´ìŒì„± íŒŒì¼ì„ ì˜ì–´ë¡œ ë°”ë¡œ ë²ˆì—­í•˜ê¸°

```jsx
Translation(text="Hello, this is a lecture on how to make a chatbot with GPT 
API. Some of you may be unfamiliar with GPT API. 
We're going to talk about how to make the program we want using 
the chat GPT function that we know well. 
So there are a lot of lectures like this. 
There are many things, but if I were to say the characteristics of this lecture,
 it's not easy to make a chatbot program that achieves a clear mission with GPT.
 I'm going to talk about how to implement this and why it's necessary. 
 As an example, there can be many examples. 
 The example here is to create a program that automatically creates a music
  playlist video through conversation. So let me show you how the program runs.
   The program we're going to make is going to look like this.")
```

05-2 ë¡œì»¬ì—ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸°

- [í—ˆê¹…í˜ì´ìŠ¤](https://huggingface.co/)(Hugging Face): ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” íšŒì‚¬, í—ˆê¹… í˜ì´ìŠ¤ í”Œë«í¼ ì„œë¹„ìŠ¤
- ìœ„ìŠ¤í¼ ëª¨ë¸ì„ ë‚´ë ¤ë°›ì•„ ë¡œì»¬ì—ì„œ ì‚¬ìš©í•˜ê¸°
    - í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ : [whisper-large-v3-turbo](https://huggingface.co/openai/whisper-large-v3-turbo), [FFMPEG](https://www.gyan.dev/ffmpeg/builds/), [íŒŒì´í† ì¹˜](https://pytorch.org/)
    - windowì—ì„œ ì‹¤í–‰ ì‹œ ì œëŒ€ë¡œ ì‹¤í–‰ ì•ˆë¨!

05-3 ë¬¸ì¥ê³¼ í™”ì êµ¬ë¶„í•˜ê¸°

- í™”ì ë¶„ë¦¬ ëª¨ë¸ë¡œ ì‹œê°„ëŒ€ë³„ í™”ì êµ¬ë¶„í•˜ê¸° 
payannote.audio ì´ìš©í•´ì„œ ê°œë°œ

```
%pip install pyannote.audio
%pip install numpy==1.26
```

```python
import os
from dotenv import load_dotenv

load_dotenv()

HUGGING_FACE_TOKEN = os.getenv("HUGGING_FACE_TOKEN")
```

```python
# instantiate the pipeline
from pyannote.audio import Pipeline

pipeline = Pipeline.from_pretrained(
  "pyannote/speaker-diarization-3.1",
  use_auth_token=HUGGING_FACE_TOKEN
)
```

```python
import torch

# cudaê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° cudaë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
if torch.cuda.is_available():
    pipeline.to(torch.device("cuda"))
    print('cuda is available')
else:
    print('cuda is not available')
```

```python
# run the pipeline on an audio file
# diarization = pipeline("audio.wav")
diarization = pipeline("../audio/ì‹¼ê¸°íƒ€_ë¹„ì‹¼ê¸°íƒ€.mp3")

# dump the diarization output to disk using RTTM format
with open("ì‹¼ê¸°íƒ€_ë¹„ì‹¼ê¸°íƒ€.rttm", "w", encoding='utf-8') as rttm:
    diarization.write_rttm(rttm)

```

05-4 íšŒì˜ë¡ì„ ì •ë¦¬í•˜ëŠ” AI ì„œê¸° ì™„ì„±í•˜ê¸°

### 6ì¥ GPT-4oë¥¼ ì´ìš©í•œ AI ì´ë¯¸ì§€ ë¶„ì„ê°€
06-1 GPT ë¹„ì „ì—ê²Œ ì´ë¯¸ì§€ ì„¤ëª… ìš”ì²­í•˜ê¸°

- [ì‹¤ìŠµ] ì¸í„°ë„·ì— ìˆëŠ” ì´ë¯¸ì§€ ì„¤ëª… ìš”ì²­í•˜ê¸°

```python
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜¤ê¸°

client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {
                "type": "image_url",
                "image_url": {
                    "url": "https://kfcapi.inicis.com/kfcs_api_img/KFCS/goods/DL_2176697_20241015131926683.png",
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
    messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
)

response
```

ChatCompletion(id='chatcmpl-CZuictHixM3G9w1xbIbDbivBFmQIf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='ì´ ì´ë¯¸ì§€ëŠ” KFCì˜ ì¹˜í‚¨ì„ ë‹´ê³  ìˆëŠ” ë²„í‚·ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë²„í‚·ì—ëŠ” ë¹¨ê°„ìƒ‰ê³¼ í°ìƒ‰ì˜ ì¤„ë¬´ëŠ¬ê°€ ìˆìœ¼ë©°, ê°€ìš´ë°ì—ëŠ” KFCì˜ ì°½ë¦½ìì˜ ì–¼êµ´ ê·¸ë¦¼ê³¼ "KFC" ë¡œê³ ê°€ ì¸ì‡„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¹˜í‚¨ì€ ì–‘ë…ì´ ë˜ì–´ ìˆì–´ ë§›ìˆì–´ ë³´ì´ëŠ” ì™¸ê´€ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.ì¹˜í‚¨ ìœ„ì— ì´‰ì´‰í•œ ì–‘ë…ì´ ë®ì—¬ìˆëŠ” ëª¨ìŠµì…ë‹ˆë‹¤. ë²„í‚·ì—ëŠ” "it\'s finger lickin\' good"ë¼ëŠ” ë¬¸êµ¬ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.', 

- [ì‹¤ìŠµ] ë‚´ê°€ ê°€ì§„ ì´ë¯¸ì§€ë¡œ ì„¤ëª… ìš”ì²­í•˜ê¸°

```python
// ì´ë¯¸ì§€ë¥¼ base54ë¡œ ë³€í™˜
import base64

# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
    
image_path = "../data/images/sajaboys.jpg"

# ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
base64_image = encode_image(image_path)

print(base64_image)
```

```
// base64ë¡œ ë³€í™˜í•œ ì´ë¯¸ì§€ ì„¤ëª… ìš”ì²­
messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{base64_image}",
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
    messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
)

response.choices[0].message.content
```

```python
// ì—¬ëŸ¬ ì´ë¯¸ì§€ ì„¤ëª… ìš”ì²­

seolleung_terrarosa_base64 = encode_image("../data/images/seolleung_terrarosa.jpg")
local_stitch_terrarosa_base64 = encode_image("../data/images/local_stitch_terrarosa.jpg")

messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "ë‘ ì¹´í˜ì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{seolleung_terrarosa_base64}",
                },
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{local_stitch_terrarosa_base64}",
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
    messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
)

response.choices[0].message.content
```

- GPT ë¹„ì „ì˜ í•œê³„ ì•Œì•„ë³´ê¸° 
- 2021, 2022ë…„ OECD ê°€ì…êµ­ì˜ ì—°êµ¬ ê°œë°œë¹„ ë¹„êµ ê·¸ë˜í”„ ë¶„ì„ ìš”ì²­

```
oecd_rnd_2021_base64 = encode_image("../data/images/oecd_rnd_2021_large.png")
oecd_rnd_2022_base64 = encode_image("../data/images/oecd_rnd_2022_large.png")

messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "ì²«ë²ˆì§¸ëŠ” 2021ë…„ ë°ì´í„°ì´ê³ , ë‘ë²ˆì§¸ëŠ” 2022ë…„ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì–´ë–¤ ë³€í™”ê°€ ìˆì—ˆë‚˜ìš”? í•œêµ­ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{oecd_rnd_2021_base64}",
                },
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{oecd_rnd_2022_base64}",
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
    messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
)

response.choices[0].message.content

```

```jsx
'2021ë…„ê³¼ 2022ë…„ ë°ì´í„°ë¥¼ ë¹„êµí–ˆì„ ë•Œ í•œêµ­ì˜ ì—°êµ¬ê°œë°œë¹„ì™€ GDP ëŒ€ë¹„ ì—°êµ¬ê°œë°œë¹„ ë¹„ì¤‘ ë³€í™”ê°€ ëˆˆì— ë•ë‹ˆë‹¤.\n\n1. **ì—°êµ¬ê°œë°œë¹„**: \n   - 2021ë…„: 89,282ë°±ë§Œ ë‹¬ëŸ¬\n   - 2022ë…„: 91,013ë°±ë§Œ ë‹¬ëŸ¬ \n   - **ì¦ê°€**: ì—°êµ¬ê°œë°œë¹„ê°€ ì•½ê°„ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.\n\n2. **GDP ëŒ€ë¹„ ì—°êµ¬ê°œë°œë¹„ ë¹„ì¤‘**: \n   - 2021ë…„ì—ëŠ” 4.93%ì˜€ë˜ ë¹„ì¤‘ì´ 2022ë…„ì—ëŠ” 5.21%ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” í•œêµ­ì´ GDP ëŒ€ë¹„ ì—°êµ¬ê°œë°œ íˆ¬ìì— ë”ìš± ë§ì€ ë¹„ì¤‘ì„ ë‘ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ë³€í™”ëŠ” í•œêµ­ì´ ì—°êµ¬ê°œë°œ ë¶„ì•¼ì— ëŒ€í•œ íˆ¬ìë¥¼ ì§€ì†ì ìœ¼ë¡œ í™•ëŒ€í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚´ë©°, ê¸°ìˆ  ë°œì „ê³¼ í˜ì‹ ì„ í†µí•œ ê²½ì œ ì„±ì¥ì— ì§‘ì¤‘í•˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.'
```

í•´ìƒë„ê°€ ì¡°ê¸ˆ ë” ë‚®ì€ ì´ë¯¸ì§€ íŒŒì¼ ì‚¬ìš©

```python
oecd_rnd_2021_base64 = encode_image("../data/images/oecd_rnd_2021_medium.png")
oecd_rnd_2022_base64 = encode_image("../data/images/oecd_rnd_2022.png")

messages = [
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "ì²«ë²ˆì§¸ëŠ” 2021ë…„ ë°ì´í„°ì´ê³ , ë‘ë²ˆì§¸ëŠ” 2022ë…„ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”. ì–´ë–¤ ë³€í™”ê°€ ìˆì—ˆë‚˜ìš”? í•œêµ­ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{oecd_rnd_2021_base64}",
                },
            },
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{oecd_rnd_2022_base64}",
                },
            },
        ],
    }
]

response = client.chat.completions.create(
    model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
    messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
)

response.choices[0].message.content

```

```jsx
'ë‘ ì´ë¯¸ì§€ì—ì„œ 2021ë…„ê³¼ 2022ë…„ì˜ ì£¼ìš” ë°ì´í„°ë¥¼ ë¹„êµí•˜ë©´ì„œ í•œêµ­ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n1. **ì—°êµ¬ê°œë°œë¹„ (R&D ì§€ì¶œ)**:\n   - **2021ë…„**: í•œêµ­ì˜ ì—°êµ¬ê°œë°œë¹„ëŠ” ì•½ 121,739ë°±ë§Œ USDì˜€ìŠµë‹ˆë‹¤.\n   - **2022ë…„**: í•œêµ­ì˜ ì—°êµ¬ê°œë°œë¹„ëŠ” ì•½ 133,867ë°±ë§Œ USDë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.\n   - ì´ëŠ” í•œêµ­ì˜ ì—°êµ¬ê°œë°œì— ëŒ€í•œ íˆ¬ì ê·œëª¨ê°€ ì¦ê°€í–ˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\n2. **GDP ëŒ€ë¹„ ì—°êµ¬ê°œë°œë¹„ ë¹„ì¤‘**:\n   - **2021ë…„**: í•œêµ­ì˜ GDP ëŒ€ë¹„ ì—°êµ¬ê°œë°œë¹„ ë¹„ì¤‘ì€ 4.93%ì˜€ìŠµë‹ˆë‹¤.\n   - **2022ë…„**: í•œêµ­ì˜ GDP ëŒ€ë¹„ ì—°êµ¬ê°œë°œë¹„ ë¹„ì¤‘ì€ 5.21%ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.\n   - ì´ëŠ” ê²½ì œ ê·œëª¨ì— ë¹„í•´ ì—°êµ¬ê°œë°œ íˆ¬ì ë¹„ìœ¨ì´ ë†’ì•„ì¡Œë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\n3. **ì£¼ìš” ë³€í™” ì‚¬í•­**:\n   - í•œêµ­ì˜ ì—°êµ¬ê°œë°œë¹„ì™€ ë¹„ì¤‘ ëª¨ë‘ ì¦ê°€í•˜ì—¬, ê²½ì œ ì„±ì¥ê³¼ í•¨ê»˜ ê¸°ìˆ  ë° í˜ì‹ ì— ëŒ€í•œ êµ­ê°€ì  ìš°ì„ ìˆœìœ„ê°€ ë†’ì•„ì¡ŒìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n   - ì„¸ê³„ì ìœ¼ë¡œ ë¯¸êµ­ê³¼ ì¤‘êµ­ë„ ì—°êµ¬ê°œë°œë¹„ ì§€ì¶œì´ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\n\nì´ëŸ° ë³€í™”ëŠ” í•œêµ­ì´ ê¸°ìˆ  í˜ì‹ ê³¼ ê³¼í•™ ì—°êµ¬ë¥¼ í†µí•´ ë¯¸ë˜ ì„±ì¥ ë™ë ¥ì„ í™•ë³´í•˜ë ¤ëŠ” ë…¸ë ¥ì„ ë°˜ì˜í•œ ê²ƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
```

- GPTì˜ ì´ë¯¸ì§€ ì¸ì‹ ê¸°ëŠ¥ì€ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ë¶„ì„ì—” ì ì ˆí•  ìˆ˜ ìˆìœ¼ë‚˜ ê·¸ë˜í”„ë¥¼ í•´ì„í•˜ê±°ë‚˜ í™˜ì CTì‚¬ì§„ì—ì„œ ì§ˆë³‘ì„ ê°ì§€í•˜ëŠ” ë“± ê³ ì°¨ì›ì ì¸ ëª©ì ì—ëŠ” ë¶€ì í•©
- ë™ì¼ ì´ë¯¸ì§€ì¸ë°ë„ ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ì™„ì „ ì˜ëª» ë‹µë³€í•¨

06-2 ì´ë¯¸ì§€ë¥¼ í™œìš©í•´ í€´ì¦ˆ ë§Œë“¤ê¸°

- [ì‹¤ìŠµ] ë¬¸ì œ ìƒì„± í•¨ìˆ˜ ë§Œë“¤ê¸°

```python
from glob import glob
from openai import OpenAI
from dotenv import load_dotenv
import os
import base64

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") 
client = OpenAI(api_key=api_key)

# ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
    

def image_quiz(image_path):
    base64_image = encode_image(image_path) # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©

    quiz_prompt = """
    ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì–‘ì‹ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 
    ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ í•´ë‹¹í•˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.
    ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 
    ----- ì˜ˆì‹œ -----

    Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?
    - (1) ë² ì´ì»¤ë¦¬ì—ì„œ ì‚¬ëŒë“¤ì´ ë¹µì„ ì‚¬ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
    - (2) ë§¨ ì•ì— ì„œ ìˆëŠ” ì‚¬ëŒì€ ë¹¨ê°„ìƒ‰ ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    - (3) ê¸°ì°¨ë¥¼ íƒ€ê¸° ìœ„í•´ ì¤„ì„ ì„œ ìˆëŠ” ì‚¬ëŒë“¤ì´ ìˆìŠµë‹ˆë‹¤.
    - (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
        
    ì •ë‹µ: (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ê°€ ì•„ë‹Œ íŒŒë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    (ì£¼ì˜: ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒë˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.)
    ======
    """

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": quiz_prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                    },
                },
            ],
        }
    ]

    response = client.chat.completions.create(
        model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •
        messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
    )

    return response.choices[0].message.content

q = image_quiz("./chap06/data/images/busan_dive.jpg")
print(q)
```

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ë§ì€ ì‚¬ëŒë“¤ì´ í…Œì´ë¸”ì— ì•‰ì•„ ë…¸íŠ¸ë¶ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- (2) ì²œì¥ì— ì—¬ëŸ¬ ê°œì˜ ì¡°ëª…ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (3) ì´ë¯¸ì§€ ì†ì—ëŠ” "DIVE 2024 IN BUSAN"ì´ë¼ëŠ” ë¬¸êµ¬ê°€ ë³´ì…ë‹ˆë‹¤.
- (4) ì‚¬ëŒë“¤ì´ ì±…ì„ ì½ê³  ìˆëŠ” ëª¨ìŠµì´ ì£¼ë¡œ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ì‚¬ëŒë“¤ì´ ì£¼ë¡œ ë…¸íŠ¸ë¶ì„ ì‚¬ìš©í•˜ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

- ì—¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë¬¸ì œì§‘ ë§Œë“¤ê¸°

```
from glob import glob
from openai import OpenAI
from dotenv import load_dotenv
import os
import base64

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") 
client = OpenAI(api_key=api_key)

# ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í•¨ìˆ˜
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
    

def image_quiz(image_path):
    base64_image = encode_image(image_path) # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©

    quiz_prompt = """
    ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì–‘ì‹ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 
    ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ í•´ë‹¹í•˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.
    ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 
    ----- ì˜ˆì‹œ -----

    Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?
    - (1) ë² ì´ì»¤ë¦¬ì—ì„œ ì‚¬ëŒë“¤ì´ ë¹µì„ ì‚¬ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
    - (2) ë§¨ ì•ì— ì„œ ìˆëŠ” ì‚¬ëŒì€ ë¹¨ê°„ìƒ‰ ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    - (3) ê¸°ì°¨ë¥¼ íƒ€ê¸° ìœ„í•´ ì¤„ì„ ì„œ ìˆëŠ” ì‚¬ëŒë“¤ì´ ìˆìŠµë‹ˆë‹¤.
    - (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
        
    ì •ë‹µ: (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ê°€ ì•„ë‹Œ íŒŒë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    (ì£¼ì˜: ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒë˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.)
    ======
    """

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": quiz_prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                    },
                },
            ],
        }
    ]

    response = client.chat.completions.create(
        model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •
        messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
    )

    return response.choices[0].message.content

# ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°›ì•„ í€´ì¦ˆë¥¼ ë§Œë“œëŠ” í•¨ìˆ˜
q = image_quiz("./chap06/data/images/busan_dive.jpg")
print(q)

txt = '' # â‘   ë¬¸ì œë“¤ì„ ê³„ì† ë¶™ì—¬ ë‚˜ê°€ê¸° ìœ„í•´ ë¹ˆ ë¬¸ìì—´ ì„ ì–¸
no = 1 # ë¬¸ì œ ë²ˆí˜¸ë¥¼ ìœ„í•´ ì„ ì–¸
for g in glob('./chap06/data/images/*.jpg'):  # â‘¡
    try:
        q = image_quiz(g) # ë¬¸ì œ ì¶œì œ (ê°€ë” GPTì—ì„œ ì—ëŸ¬ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ tryë¬¸ ì‚¬ìš©)
    except Exception as e:
        print(e)
        continue

    divider = f'## ë¬¸ì œ {no}\n\n'
    print(divider)
    
    txt += divider  # â‘¢
    # íŒŒì¼ëª… ì¶”ì¶œí•´ ì´ë¯¸ì§€ ë§í¬ ë§Œë“¤ê¸°
    filename = os.path.basename(g) # â‘¢ ë§ˆí¬ë‹¤ìš´ì— í‘œì‹œí•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •   
    txt += f'![image]({filename})\n\n' # â‘¢

    # ë¬¸ì œ ì¶”ê°€
    print(q)
    txt += q + '\n\n---------------------\n\n'
    # â‘£ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    with open('./chap06/data/images/image_quiz.md', 'w', encoding='utf-8') as f:
        f.write(txt)
    
    no += 1 # ë¬¸ì œ ë²ˆí˜¸ ì¦ê°€

```

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ë§ì€ ì‚¬ëŒë“¤ì´ ì±…ìƒì— ì•‰ì•„ ì»´í“¨í„° ì‘ì—…ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- (2) ì²œì¥ì—ëŠ” ì—¬ëŸ¬ ê°œì˜ ì¡°ëª…ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (3) ë°°ê²½ì—ëŠ” "DIVE 2024 IN BUSAN"ì´ë¼ëŠ” ê¸€ìê°€ ë³´ì…ë‹ˆë‹¤.
- (4) ëª¨ë“  ì‚¬ëŒì´ ë™ì¼í•œ ìƒ‰ì˜ ì˜·ì„ ì…ê³  ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ëª¨ë“  ì‚¬ëŒì´ ë™ì¼í•œ ìƒ‰ì˜ ì˜·ì„ ì…ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ìƒ‰ì˜ ì˜·ì„ ì…ê³  ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ 1

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ë§ì€ ì‚¬ëŒë“¤ì´ ì±…ìƒì— ì•‰ì•„ ë¬´ì–¸ê°€ë¥¼ ì‘ì—…í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- (2) ì²œì¥ì— ì¡°ëª…ì´ ì—¬ëŸ¬ ê°œ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (3) í–‰ì‚¬ ì´ë¦„ì´ "DIVE 2024 in BUSAN"ì´ë¼ê³  ì í˜€ ìˆìŠµë‹ˆë‹¤.
- (4) ì‚¬ëŒë“¤ì´ ì±…ì„ ì½ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ì‚¬ëŒë“¤ì´ ì±…ì„ ì½ê³  ìˆëŠ” ëª¨ìŠµì´ ì•„ë‹Œ, ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•˜ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ 2

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ì„¸ ëª…ì˜ ìºë¦­í„°ê°€ ì†ŒíŒŒì— ì•‰ì•„ ìˆìŠµë‹ˆë‹¤.
- (2) ê°€ìš´ë° ìºë¦­í„°ëŠ” ì§§ì€ ë¨¸ë¦¬ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- (3) í…Œì´ë¸” ìœ„ì—ëŠ” ë‹¤ì–‘í•œ ìŒì‹ì´ ë†“ì—¬ ìˆìŠµë‹ˆë‹¤.
- (4) ì˜¤ë¥¸ìª½ ìºë¦­í„°ëŠ” ë…¸ë€ìƒ‰ ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ì˜¤ë¥¸ìª½ ìºë¦­í„°ëŠ” ë…¸ë€ìƒ‰ ì…”ì¸ ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ìƒ‰ì˜ ì˜ìƒì„ ì…ê³  ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ 3

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) í° ë…¸ë€ìƒ‰ ì¡°í˜•ë¬¼ì´ ë³´ì…ë‹ˆë‹¤.
- (2) ê±´ë¬¼ì— "Local Stitch"ë¼ëŠ” ê¸€ìê°€ ì“°ì—¬ ìˆìŠµë‹ˆë‹¤.
- (3) ê²€ì€ìƒ‰ ì˜ìê°€ ìˆìŠµë‹ˆë‹¤.
- (4) ì‚¬ëŒë“¤ì´ ë²½ì— ì„œì„œ í¬ì¦ˆë¥¼ ì·¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ì‚¬ëŒë“¤ì€ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ë¬¸ì œ 4

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ì¹´í˜ ë‚´ë¶€ì— ì—¬ëŸ¬ ê°œì˜ í…Œì´ë¸”ê³¼ ì˜ìê°€ ìˆìŠµë‹ˆë‹¤.
- (2) ë°”ë¦¬ìŠ¤íƒ€ê°€ ìŒë£Œë¥¼ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤.
- (3) ë°”ë‹¥ì€ íŒŒë€ìƒ‰ê³¼ ë¹¨ê°„ìƒ‰ íƒ€ì¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (4) ì¹´ìš´í„° ë’¤ë²½ì€ ë…¸ë€ìƒ‰ì…ë‹ˆë‹¤.

ì •ë‹µ: (3) ë°”ë‹¥ì€ íŒŒë€ìƒ‰ê³¼ ë¹¨ê°„ìƒ‰ íƒ€ì¼ì´ ì•„ë‹Œ, í°ìƒ‰ê³¼ ë¹¨ê°„ìƒ‰ íƒ€ì¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ 5

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ê±´ë¬¼ ì™¸ê´€ì€ ë²½ëŒë¡œ ë§ˆê°ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (2) 1ì¸µ ì°½ë¬¸ì—ëŠ” "PERSONAL COFFEE"ë¼ëŠ” ë¬¸êµ¬ê°€ ë³´ì…ë‹ˆë‹¤.
- (3) ê±´ë¬¼ ì•ì— ì£¼í™©ìƒ‰ ì›ë¿” ëª¨ì–‘ì˜ ì¥ì• ë¬¼ì´ ìˆìŠµë‹ˆë‹¤.
- (4) ê±´ë¬¼ì€ ë‹¨ì¸µ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ê±´ë¬¼ì€ ë‹¨ì¸µ êµ¬ì¡°ê°€ ì•„ë‹Œ ì—¬ëŸ¬ ì¸µìœ¼ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ 6

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë¹µì´ ì§„ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (2) ì§„ì—´ëŒ€ ìœ„ì—ëŠ” ê°€ê²©í‘œê°€ ë¶€ì°©ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (3) ë² ì´ì»¤ë¦¬ ì§ì›ë“¤ì€ ëª¨ìë¥¼ ì“°ê³  ìˆìŠµë‹ˆë‹¤.
- (4) ì˜¤ë¥¸ìª½ì—ëŠ” ì¼€ì´í¬ê°€ ì§„ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (4) ì˜¤ë¥¸ìª½ì—ëŠ” ì¼€ì´í¬ê°€ ì•„ë‹Œ ë¹µì´ ì§„ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ë¬¸ì œ 7

I'm unable to create questions about the identities of people in the image, but I can assist with general descriptions. Hereâ€™s a quiz based on the image itself:

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ë‹¤ì„¯ ëª…ì˜ ì‚¬ëŒë“¤ì´ í¬ì¦ˆë¥¼ ì·¨í•˜ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
- (2) ê°€ìš´ë° ìˆëŠ” ì‚¬ëŒì€ í° ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
- (3) ì‚¬ëŒë“¤ ëª¨ë‘ ë°”ì§€ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
- (4) ëª¨ë“  ì‚¬ëŒì˜ ë¨¸ë¦¬ìƒ‰ì´ ìì—° ê°ˆìƒ‰ì…ë‹ˆë‹¤.

ì •ë‹µ: (4) ëª¨ë“  ì‚¬ëŒì˜ ë¨¸ë¦¬ìƒ‰ì´ ìì—° ê°ˆìƒ‰ì´ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ìƒ‰ìƒì…ë‹ˆë‹¤.

## ë¬¸ì œ 8

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) "bakery cafe pomme verte"ë¼ëŠ” ê°„íŒì´ ë³´ì…ë‹ˆë‹¤.
- (2) ì‘ì—…ìë“¤ì´ ê³µì‚¬ë¥¼ í•˜ê³  ìˆëŠ” ì¥ë©´ì…ë‹ˆë‹¤.
- (3) ì˜¤ë¥¸ìª½ ìƒì ì˜ ì´ë¦„ì€ "ë‰´íŠ¸ë¦¬ì½”ì–´"ì…ë‹ˆë‹¤.
- (4) ì´ë¯¸ì§€ì—ëŠ” ì‚¬ëŒë“¤ì´ ë„ë¡œë¥¼ ê±´ë„ˆê°€ê³  ìˆëŠ” ëª¨ìŠµì´ ë‚˜ì˜µë‹ˆë‹¤.

ì •ë‹µ: (4) ì´ë¯¸ì§€ì—ëŠ” ì‚¬ëŒë“¤ì´ ë„ë¡œë¥¼ ê±´ë„ˆê°€ê³  ìˆëŠ” ëª¨ìŠµì´ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ë¬¸ì œ 9

---

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ì—¬ëŸ¬ ì‚¬ëŒë“¤ì´ í…Œì´ë¸”ì— ì•‰ì•„ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ê³  ìˆìŠµë‹ˆë‹¤.
- (2) ì²œì¥ì— ë§ì€ ì¡°ëª…ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- (3) ë°”ë‹¥ì€ ì§™ì€ ìƒ‰ì˜ ì¹´í«ìœ¼ë¡œ ë®ì—¬ ìˆìŠµë‹ˆë‹¤.
- (4) ì°½ë¬¸ìœ¼ë¡œ ë°”ê¹¥ì˜ í’ê²½ì´ ë³´ì…ë‹ˆë‹¤.

ì •ë‹µ: (3) ë°”ë‹¥ì€ ì§™ì€ ìƒ‰ì˜ ì¹´í«ì´ ì•„ë‹Œ ë‚˜ë¬´ ë°”ë‹¥ì…ë‹ˆë‹¤.

---

## ë¬¸ì œ 10

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) ë§ì€ ì‚¬ëŒë“¤ì´ ë²„ìŠ¤ ì˜†ì— ëª¨ì—¬ ìˆìŠµë‹ˆë‹¤.
- (2) ì°½ë¬¸ì— 'CAMERA'ë¼ëŠ” ê¸€ìê°€ ë³´ì…ë‹ˆë‹¤.
- (3) ë‚˜ë¬´ë“¤ì´ ìì‚¬ê·€ë¥¼ í’ì„±í•˜ê²Œ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
- (4) í•œ ì‚¬ëŒì´ ì „í™” í†µí™”ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ì •ë‹µ: (2) ì°½ë¬¸ì— 'CAMERA'ë¼ëŠ” ê¸€ìê°€ ì•„ë‹Œ 'COFFEE & BAKERY'ë¼ëŠ” ê¸€ìê°€ ë³´ì…ë‹ˆë‹¤.

- ì˜ì–´ë¡œ ë¬¸ì œ ì¶œì œí•˜ê¸°

```python

from glob import glob 
from openai import OpenAI
from dotenv import load_dotenv
import os
import base64

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") 
client = OpenAI(api_key=api_key)  
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
    

def image_quiz(image_path, n_trial=0, max_trial=3): # ì˜¤í”ˆAI API í˜¸ì¶œì— ì‹¤íŒ¨í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì¬ê·€ì ìœ¼ë¡œ ì¬ì‹œë„
    if n_trial >= max_trial: # ìµœëŒ€ ì‹œë„ íšŒìˆ˜ì— ë„ë‹¬í•˜ë©´ í¬ê¸°
        raise Exception("Failed to generate a quiz.")
    
    base64_image = encode_image(image_path) # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©

    quiz_prompt = """
    ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì–‘ì‹ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 
    ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ í•´ë‹¹í•˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.
    í† ìµ ë¦¬ìŠ¤ë‹ ë¬¸ì œ ìŠ¤íƒ€ì¼ë¡œ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 
    ----- ì˜ˆì‹œ -----

    Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?
    - (1) ë² ì´ì»¤ë¦¬ì—ì„œ ì‚¬ëŒë“¤ì´ ë¹µì„ ì‚¬ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
    - (2) ë§¨ ì•ì— ì„œ ìˆëŠ” ì‚¬ëŒì€ ë¹¨ê°„ìƒ‰ ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    - (3) ê¸°ì°¨ë¥¼ íƒ€ê¸° ìœ„í•´ ì¤„ì„ ì„œ ìˆëŠ” ì‚¬ëŒë“¤ì´ ìˆìŠµë‹ˆë‹¤.
    - (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.

    Listening: Which of the following descriptions of the image is incorrect?
    - (1) It shows people buying bread at a bakery.
    - (2) The person standing at the front is wearing a red shirt.
    - (3) There are people lining up to take a train.
    - (4) The clerk is wearing a yellow T-shirt.
        
    ì •ë‹µ: (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ê°€ ì•„ë‹Œ íŒŒë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    (ì£¼ì˜: ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒë˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.)
    ======
    """

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": quiz_prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                    },
                },
            ],
        }
    ]

    try: 
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
        )
    except Exception as e:
        print("failed\n" + e)
        return image_quiz(image_path, n_trial+1)
    
    content = response.choices[0].message.content

    if "Listening:" in content:
        return content, True
    else:
        return image_quiz(image_path, n_trial+1)

q = image_quiz("./chap06/data/images/busan_dive.jpg")
print(q)

txt = '' # â‘   ë¬¸ì œë“¤ì„ ê³„ì† ë¶™ì—¬ ë‚˜ê°€ê¸° ìœ„í•´ ë¹ˆ ë¬¸ìì—´ ì„ ì–¸
no = 1 # ë¬¸ì œ ë²ˆí˜¸ë¥¼ ìœ„í•´ ì„ ì–¸
for g in glob('./chap06/data/images/*.jpg'):  # â‘¡
    q, is_suceed = image_quiz(g)

    if not is_suceed:
        continue

    divider = f'## ë¬¸ì œ {no}\n\n'
    print(divider)
    
    txt += divider  # â‘¢
    # íŒŒì¼ëª… ì¶”ì¶œí•´ ì´ë¯¸ì§€ ë§í¬ ë§Œë“¤ê¸°
    filename = os.path.basename(g) # â‘¢ ë§ˆí¬ë‹¤ìš´ì— í‘œì‹œí•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •   
    txt += f'![image]({filename})\n\n' # â‘¢

    # ë¬¸ì œ ì¶”ê°€
    print(q)
    txt += q + '\n\n---------------------\n\n'
    # â‘£ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    with open('./chap06/data/images/image_quiz_eng.md', 'w', encoding='utf-8') as f:
        f.write(txt)
    
    no += 1 # ë¬¸ì œ ë²ˆí˜¸ ì¦ê°€

```

```markdown
## ë¬¸ì œ 1

![image](busan_dive.jpg)

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?

- (1) í–‰ì‚¬ì¥ ë‚´ë¶€ì— ë§ì€ ì‚¬ëŒë“¤ì´ ì•‰ì•„ ìˆìŠµë‹ˆë‹¤.
- (2) ì¤‘ì•™ì— ìˆëŠ” í° ìŠ¤í¬ë¦°ì€ "DIVE 2024 IN BUSAN"ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.
- (3) ëª¨ë“  ì°¸ê°€ìë“¤ì´ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
- (4) í–‰ì‚¬ì¥ì€ ì‹¤ë‚´ì— ìˆìŠµë‹ˆë‹¤.

Listening: Which of the following descriptions of the image is incorrect?

- (1) Many people are seated inside the venue.
- (2) The large screen in the center displays "DIVE 2024 IN BUSAN."
- (3) All participants are wearing yellow T-shirts.
- (4) The event is held indoors.

ì •ë‹µ: (3) ëª¨ë“  ì°¸ê°€ìë“¤ì´ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.

---------------------

## ë¬¸ì œ 2

![image](kdemon.jpg)

Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?
- (1) ì„¸ ëª…ì˜ ì‚¬ëŒì´ ì†ŒíŒŒì— ì•‰ì•„ ìˆìŠµë‹ˆë‹¤.
- (2) í…Œì´ë¸” ìœ„ì—ëŠ” ë‹¤ì–‘í•œ ìŒì‹ì´ ë†“ì—¬ ìˆìŠµë‹ˆë‹¤.
- (3) í•œ ì‚¬ëŒì€ ë…¸ë€ìƒ‰ ì¬í‚·ì„ ì…ê³  ìˆìŠµë‹ˆë‹¤.
- (4) ë°°ê²½ì— ì°½ë¬¸ì´ í¬ê²Œ ë³´ì…ë‹ˆë‹¤.

Listening: Which of the following descriptions of the image is incorrect?
- (1) Three people are sitting on the couch.
- (2) A variety of food is placed on the table.
- (3) One person is wearing a yellow jacket.
- (4) A large window is prominently seen in the background.

ì •ë‹µ: (4) ë°°ê²½ì— ì°½ë¬¸ì´ í¬ê²Œ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤.
....
```

- [ì‹¤ìŠµ] TTSë¡œ ì˜ì–´ ë“£ê¸° í‰ê°€ ë¬¸ì œ ë§Œë“¤ê¸°

```python
from glob import glob 
import json
from openai import OpenAI
from dotenv import load_dotenv
import os
import base64

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") 
client = OpenAI(api_key=api_key)  

def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")
    

def image_quiz(image_path, n_trial=0, max_trial=3):
    if n_trial >= max_trial: # ìµœëŒ€ ì‹œë„ íšŒìˆ˜ì— ë„ë‹¬í•˜ë©´ í¬ê¸°
        raise Exception("Failed to generate a quiz.")
    
    base64_image = encode_image(image_path) # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©

    quiz_prompt = """
    ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ì–‘ì‹ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”. 
    ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ í•´ë‹¹í•˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.
    í† ìµ ë¦¬ìŠ¤ë‹ ë¬¸ì œ ìŠ¤íƒ€ì¼ë¡œ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
    ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 
    ----- ì˜ˆì‹œ -----

    Q: ë‹¤ìŒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì§€ ì•Šì€ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?
    - (1) ë² ì´ì»¤ë¦¬ì—ì„œ ì‚¬ëŒë“¤ì´ ë¹µì„ ì‚¬ê³  ìˆëŠ” ëª¨ìŠµì´ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
    - (2) ë§¨ ì•ì— ì„œ ìˆëŠ” ì‚¬ëŒì€ ë¹¨ê°„ìƒ‰ ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    - (3) ê¸°ì°¨ë¥¼ íƒ€ê¸° ìœ„í•´ ì¤„ì„ ì„œ ìˆëŠ” ì‚¬ëŒë“¤ì´ ìˆìŠµë‹ˆë‹¤.
    - (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.

    Listening: Which of the following descriptions of the image is incorrect?
    - (1) It shows people buying bread at a bakery.
    - (2) The person standing at the front is wearing a red shirt.
    - (3) There are people lining up to take a train.
    - (4) The clerk is wearing a yellow T-shirt.
        
    ì •ë‹µ: (4) ì ì›ì€ ë…¸ë€ìƒ‰ í‹°ì…”ì¸ ê°€ ì•„ë‹Œ íŒŒë€ìƒ‰ í‹°ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤.
    (ì£¼ì˜: ì •ë‹µì€ 1~4 ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒë˜ë„ë¡ ì¶œì œí•˜ì„¸ìš”.)
    ======
    """

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": quiz_prompt},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                    },
                },
            ],
        }
    ]

    try: 
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
        )
    except Exception as e:
        print("failed\n" + e)
        return image_quiz(image_path, n_trial+1)
    
    content = response.choices[0].message.content

    if "Listening:" in content:
        return content, True
    else:
        return image_quiz(image_path, n_trial+1)

txt = '' # ë¬¸ì œë“¤ì„ ê³„ì† ë¶™ì—¬ ë‚˜ê°€ê¸° ìœ„í•´ ë¹ˆ ë¬¸ìì—´ ì„ ì–¸
eng_dict = []
no = 1 # ë¬¸ì œ ë²ˆí˜¸ë¥¼ ìœ„í•´ ì„ ì–¸
for g in glob('./chap06/data/images/*.jpg'):  # â‘¡
    q, is_suceed = image_quiz(g)

    if not is_suceed:
        continue

    divider = f'## ë¬¸ì œ {no}\n\n'
    print(divider)
    
    txt += divider 
    # íŒŒì¼ëª… ì¶”ì¶œí•´ ì´ë¯¸ì§€ ë§í¬ ë§Œë“¤ê¸°
    filename = os.path.basename(g) # â‘¢ ë§ˆí¬ë‹¤ìš´ì— í‘œì‹œí•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •   
    txt += f'![image]({filename})\n\n' 

    # ë¬¸ì œ ì¶”ê°€
    print(q)
    txt += q + '\n\n---------------------\n\n'
    # â‘£ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    with open('./chap06/data/images/image_quiz_eng.md', 'w', encoding='utf-8') as f:
        f.write(txt)

    # ì˜ì–´ ë¬¸ì œë§Œ ì¶”ì¶œ
    eng = q.split('Listening: ')[1].split('ì •ë‹µ:')[0].strip()    

    eng_dict.append({
        'no': no,
        'eng': eng,
        'img': filename
    })

    # json íŒŒì¼ë¡œ ì €ì¥
    with open('./chap06/data/images/image_quiz_eng.json', 'w', encoding='utf-8') as f:
        json.dump(eng_dict, f, ensure_ascii=False, indent=4)

    no += 1 # ë¬¸ì œ ë²ˆí˜¸ ì¦ê°€

```

json íŒŒì¼

```json
[
    {
        "no": 1,
        "eng": "Which of the following descriptions of the image is incorrect?\n- (1) Many people are sitting at desks working.\n- (2) There is a large display board on the wall.\n- (3) The lights in the room are turned off.\n- (4) There are structures visible at the top of the image.",
        "img": "busan_dive.jpg"
    },
    {
        "no": 2,
        "eng": "Which of the following descriptions of the image is incorrect?\n- (1) Three people are sitting around a table.\n- (2) The person in the middle has purple hair.\n- (3) There are various foods on the table.\n- (4) The person on the left is wearing yellow clothes.",
        "img": "kdemon.jpg"
    },
    {
        "no": 3,
        "eng": "Which of the following descriptions of the image is incorrect?\n- (1) A yellow sculpture is located in the center.\n- (2) The background building has the word \"Local Stitch\" visible.\n- (3) A bench is located on the right side of the image.\n- (4) There is a space with trees planted in the image.",
        "img": "local_stitch.jpg"
    },
    {
        "no": 4,
        "eng": "Which of the following descriptions of the image is incorrect?\n- (1) People are sitting in the cafÃ©.\n- (2) Large windows surround the cafÃ©.\n- (3) One person is standing in front of the cashier.\n- (4) The cafÃ© walls are yellow and white.",
        "img": "local_stitch_terrarosa.jpg"
    },
    {
        "no": 5,
        "eng": "Which of the following descriptions of the image is incorrect?\n\n- (1) There is a coffee shop on the second floor.\n- (2) The building's exterior is made of red bricks.\n- (3) A no parking sign is visible.\n- (4) An orange cone is placed on the sidewalk.",
        "img": "mangwon.jpg"
    },
    {
        "no": 6,
        "eng": "Which of the following descriptions of the image is incorrect?\n- (1) Various types of bread are displayed.\n- (2) The staff member is wearing a hat.\n- (3) The price tags of the bread are not visible.\n- (4) A glass display case is used.",
        "img": "mangwon_bakery.jpg"
    }
]
```

tts.ipynb
ì˜¤í”ˆAI API ì„¤ì •í•˜ê¸° 

```
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") 
client = OpenAI(api_key=api_key)  
```

ì˜¤í”ˆAI TTS ê³µì‹ ë¬¸ì„œ(https://platform.openai.com/docs/guides/text-to-speech)

ì²«ë²ˆì§¸ TTS í…ŒìŠ¤íŠ¸

```python
response = client.audio.speech.create(
    model="tts-1-hd",
    voice="echo", // ì±…ê³¼ ë‹¤ë¥¸ ëª©ì†Œë¦¬ ì„ íƒ
    input="Hello world! This is a TTS test.",
)

response.write_to_file("hello_world.mp3")

# ì¬ìƒ
import IPython.display as ipd

ipd.Audio("hello_world.mp3")
```

ëª©ì†Œë¦¬ ë°”ê¾¸ê³  í…ŒìŠ¤íŠ¸

```python
# ë‹¤ë¥¸ ëª©ì†Œë¦¬
voice = "ash"
mp3_file = f"hello_world_{voice}.mp3"

response = client.audio.speech.create(
    model="tts-1-hd",
    voice=voice,
    input=f"Hello world! I'm {voice}. This is a TTS test.",
)

response.write_to_file(mp3_file)

# ì¬ìƒ
import IPython.display as ipd

ipd.Audio(mp3_file)
```

ì˜ì–´ ìŠ¤í¬ë¦½íŠ¸ jsoníŒŒì¼ ì½ê¸°

```python
import json

# json íŒŒì¼ ì—´ê¸°
with open('../data/images/image_quiz_eng.json', 'r', encoding='utf-8') as f:
    eng_dict = json.load(f)

eng_dict

```
mp3 íŒŒì¼ ì¬ìƒ

ipd.Audio(f"../data/audio/1.mp3")

### 7ì¥ ìµœì‹  ì£¼ì‹ ì •ë³´ë¥¼ ì•Œë ¤ ì£¼ëŠ” AI íˆ¬ìì 
07-1 í‘ì…˜ ì½œë§ì˜ ê¸°ì´ˆ
- í‘ì…˜ ì½œë§ì´ë€?
LLMì´ ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì„ ì´í•´í•˜ê³ , ì´ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ì •ì˜ëœ ì™¸ë¶€ í•¨ìˆ˜(API)ë¥¼ ìë™ìœ¼ë¡œ í˜¸ì¶œí•˜ëŠ” ê¸°ìˆ , LLMì€ ë‹¨ìˆœí•œ ì •ë³´ ì œê³µì„ ë„˜ì–´ ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ì—°ë™í•  ìˆ˜ ìˆê²Œ ëœë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ ì§€ê¸ˆ ëª‡ì‹œì•¼? ë¬¼ì–´ë³´ë©´ gptëŠ” ë„êµ¬ ëª©ë¡ì—ì„œ ì‹œê°„ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë¥¼ ì°¾ì•„ì„œ ê·¸ ë„êµ¬ë¥¼ ì‚¬ìš© í•´ì„œ ë‹µë³€í•¨.
ë„êµ¬ ëª©ë¡ì˜ ë”•ì…”ë„ˆë¦¬ëŠ” GPTëª¨ë¸ì´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì§€ ì•Œë ¤ì£¼ëŠ” ì„¤ëª…ì„œ ì—­í• ì„ í•˜ë©°, GPT  APIë¥¼ í˜¸ì¶œí•  ë•Œ ì´ ë„êµ¬ ëª©ë¡ë„ í•¨ê»˜ ì „ë‹¬ë¨
ì–´ë–¤ ê±¸ ë¬¼ì–´ë´¤ì„ ë•Œ â€˜ë¶„ì„ì¤‘â€¦â€™ ì´ë ‡ê²Œ ëœ¨ëŠ” ê±°ë©´ í‘ì…˜ ì½œë§ ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¤‘ì„.
    - [ì‹¤ìŠµ] í‘ì…˜ ì½œë§ ì ìš©í•˜ê¸°
    
    ```python
    // GPTë¥¼ ìœ„í•´ ì‚¬ìš©í•  í•¨ìˆ˜ ì •ì˜ ë° ì„¤ëª… ì¶”ê°€
    from datetime import datetime
    
    def get_current_time():
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(now)
        return now
    
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_current_time",
                "description": "í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.", #ë§¤ê°œë³€ìˆ˜ê°€ ì—†ìœ¼ë¯€ë¡œ íŒŒë¼ë¯¸í„° ìƒëµ
            }
        },
    ]
    
    if __name__ == '__main__':
        get_current_time()  
        
        # 2025-11-11 23:08:00
    ```
    
    ```python
    from gpt_functions import get_current_time, tools 
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY") 
    
    client = OpenAI(api_key=api_key)
    
    def get_ai_response(messages, tools=None):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
        )
        return response  # ìƒì„±ëœ ì‘ë‹µ ë‚´ìš© ë°˜í™˜
    
    messages = [
        {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
    ]
    
    while True:
        user_input = input("ì‚¬ìš©ì\t: ")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    
        if user_input == "exit":  # ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ëŠ”ì§€ í™•ì¸
            break
        
        messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        
        ai_response = get_ai_response(messages, tools=tools)
        ai_message = ai_response.choices[0].message
        print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            tool_name = tool_calls[0].function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
            tool_call_id = tool_calls[0].id         # tool_call ì•„ì´ë”” ë°›ê¸°    
            
            if tool_name == "get_current_time":  # ë§Œì•½ tool_nameì´ "get_current_time"ì´ë¼ë©´
                messages.append({
                    "role": "function",  # roleì„ "function"ìœ¼ë¡œ ì„¤ì •
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": get_current_time(),  # get_current_time í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ë¥¼ contentë¡œ ì„¤ì •
                })
    
            ai_response = get_ai_response(messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        messages.append(ai_message)  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê¸°
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
    
    ```
    

- [ì‹¤ìŠµ] ë„ì‹œë³„ ì‹œê°„ ì•Œë ¤ ì£¼ê¸°

```
// íƒ€ì„ì¡´ ì •ë³´ë¥¼ ì´ìš©í•´ í˜„ì¬ ì‹œê°„ì„ êµ¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •
from datetime import datetime
import pytz 

def get_current_time(timezone: str = 'Asia/Seoul'):
    tz = pytz.timezone(timezone) # íƒ€ì„ì¡´ ì„¤ì •
    now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
    now_timezone = f'{now} {timezone}'
    print(now_timezone)
    return now_timezone

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_current_time",
            "description": "í•´ë‹¹ íƒ€ì„ì¡´ì˜ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    'timezone': {
                        'type': 'string',
                        'description': 'í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•  íƒ€ì„ì¡´ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: Asia/Seoul)',
                    },
                },
                "required": ['timezone'],
            },        
        }
    },
]

if __name__ == '__main__':
    get_current_time('America/New_York')
```

```python
from gpt_functions import get_current_time, tools 
from openai import OpenAI
from dotenv import load_dotenv
import os
import json

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")  

client = OpenAI(api_key=api_key)

def get_ai_response(messages, tools=None):
    response = client.chat.completions.create(
        model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
        messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
        tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
    )
    return response  # ìƒì„±ëœ ì‘ë‹µ ë‚´ìš© ë°˜í™˜

messages = [
    {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
]

while True:
    user_input = input("ì‚¬ìš©ì\t: ")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°

    if user_input == "exit":  # ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ëŠ”ì§€ í™•ì¸
        break
    
    messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    
    ai_response = get_ai_response(messages, tools=tools)
    ai_message = ai_response.choices[0].message
    print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€

    tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
        tool_name = tool_calls[0].function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
        tool_call_id = tool_calls[0].id         # í•¨ìˆ˜ ì•„ì´ë”” ë°›ê¸°    
        arguments = json.loads(tool_calls[0].function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
        
        if tool_name == "get_current_time":  #tool_nameì´ "get_current_time"ì´ë¼ë©´
            messages.append({
                "role": "function",  # roleì„ "function"ìœ¼ë¡œ ì„¤ì •
                "tool_call_id": tool_call_id,
                "name": tool_name,
                "content": get_current_time(timezone=arguments['timezone']),  # íƒ€ì„ì¡´ ì¶”ê°€
            })

        ai_response = get_ai_response(messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
        ai_message = ai_response.choices[0].message

    messages.append(ai_message)  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê¸°

    print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥

```

    

- [ì‹¤ìŠµ] ì—¬ëŸ¬ ë„ì‹œì˜ ì‹œê°„ì„ í•œ ë²ˆì— ëŒ€ë‹µí•  ìˆ˜ ìˆê²Œ í•˜ê¸°
    
    ```python
    from gpt_functions import get_current_time, tools 
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY") 
    
    client = OpenAI(api_key=api_key) 
    
    def get_ai_response(messages, tools=None):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
        )
        return response  # ìƒì„±ëœ ì‘ë‹µ ë‚´ìš© ë°˜í™˜
    
    messages = [
        {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
    ]
    
    while True:
        user_input = input("ì‚¬ìš©ì\t: ")  # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    
        if user_input == "exit":  # ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ë ¤ëŠ”ì§€ í™•ì¸
            break
        
        messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        
        ai_response = get_ai_response(messages, tools=tools)
        ai_message = ai_response.choices[0].message
        print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls: # í•¨ìˆ˜ ê²°ê³¼ ê³„ì† ì¶”ê°€
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) #ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  # ë§Œì•½ tool_nameì´ "get_current_time"ì´ë¼ë©´
                    messages.append({
                        "role": "function",  # roleì„ "function"ìœ¼ë¡œ ì„¤ì •
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "content": get_current_time(timezone=arguments['timezone']),  # íƒ€ì„ì¡´ ì¶”ê°€
                    })
            messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."})  # í•¨ìˆ˜ ì‹¤í–‰ ì™„ë£Œ ë©”ì‹œì§€ ì¶”ê°€
            ai_response = get_ai_response(messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        messages.append(ai_message)  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•˜ê¸°
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
    
    ```
    

- [ì‹¤ìŠµ] ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ í‘ì…˜ ì½œë§ ì‚¬ìš©í•˜ê¸°
    
    ```
    from gpt_functions import get_current_time, tools 
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")  
    
    client = OpenAI(api_key=api_key)  
    
    def get_ai_response(messages, tools=None):
        response = client.chat.completions.create(
            model="gpt-4o",  
            messages=messages,  
            tools=tools,  
        )
        return response 
    
    st.title("ğŸ’¬ AI Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."}
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        ai_message = ai_response.choices[0].message
        print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) # (1) ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  # â‘¤ ë§Œì•½ tool_nameì´ "get_current_time"ì´ë¼ë©´
                    st.session_state.messages.append({
                        "role": "function",  # roleì„ "function"ìœ¼ë¡œ ì„¤ì •
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "content": get_current_time(timezone=arguments['timezone']),  # íƒ€ì„ì¡´ ì¶”ê°€
                    })
            st.session_state.messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": ai_message.content
        })  # â‘¢ AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
        st.chat_message("assistant").write(ai_message.content)  # ë¸Œë¼ìš°ì €ì— ë©”ì‹œì§€ ì¶œë ¥
    ```
07-2 GPTì™€ ë¯¸êµ­ ì£¼ì‹ ì´ì•¼ê¸°í•˜ê¸°
yfinance: ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ì˜ ê¸ˆìœµ ë°ì´í„°ë¥¼ ì‰½ê²Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤, ì£¼ê°€, ì¬ë¬´ì œí‘œ, ê±°ë˜ëŸ‰ ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ ë°ì´í„° í”„ë ˆì„ í˜•íƒœë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ 

- [ì‹¤ìŠµ] yfinance ì‚¬ìš©í•˜ê¸°

```python
%pip install yfinance

import yfinance as yf

# Microsoft (MSFT)ì— ëŒ€í•œ Ticker(ê¸ˆìœµ ìƒí’ˆ ì‹ë³„í•˜ëŠ” ê³ ìœ  ì½”ë“œ) ê°ì²´ ìƒì„±
msft = yf.Ticker("MSFT")

# Ticker ê°ì²´ì— ëŒ€í•œ ì •ë³´ ì¶œë ¥ (.pyì—ì„œ ì‹¤í–‰í•  ë•ŒëŠ” print(msft.info)ë¡œ ì‚¬ìš©)
display(msft.info)
```

```python
// ì‹¤í–‰ ê²°ê³¼

{'address1': 'One Microsoft Way',
 'city': 'Redmond',
 'state': 'WA',
 'zip': '98052-6399',
 'country': 'United States',
 'phone': '425 882 8080',
 'website': '
 [https://www.microsoft.com](https://www.microsoft.com/)
 ',
 'industry': 'Software - Infrastructure',
 'industryKey': 'software-infrastructure',
 'industryDisp': 'Software - Infrastructure',
 'sector': 'Technology',
 'sectorKey': 'technology',
 'sectorDisp': 'Technology',
 'longBusinessSummary': "Microsoft Corporation develops and supports software, services, devices, and solutions worldwide. The company's Productivity and Business Processes segment offers Microsoft 365 Commercial, Enterprise Mobility + Security, Windows Commercial, Power BI, Exchange, SharePoint, Microsoft Teams, Security and Compliance, and Copilot; Microsoft 365 Commercial products, such as Windows Commercial on-premises and Office licensed services; Microsoft 365 Consumer products and cloud services, such as Microsoft 365 Consumer subscriptions, Office licensed on-premises, and other consumer services; LinkedIn; Dynamics products and cloud services, such as Dynamics 365, cloud-based applications, and on-premises ERP and CRM applications. Its Intelligent Cloud segment provides Server products and cloud services, such as Azure and other cloud services, GitHub, Nuance Healthcare, virtual desktop offerings, and other cloud services; Server products, including SQL and Windows Server, Visual Studio and System Center related Client Access Licenses, and other on-premises offerings; Enterprise and partner services, including Enterprise Support and Nuance professional Services, Industry Solutions, Microsoft Partner Network, and Learning Experience. The company's Personal Computing segment provides Windows and Devices, such as Windows OEM licensing and Devices and Surface and PC accessories; Gaming services and solutions, such as Xbox hardware, content, and services, first- and third-party content Xbox Game Pass, subscriptions, and Cloud Gaming, advertising, and other cloud services; search and news advertising services, such as Bing and Copilot, Microsoft News and Edge, and third-party affiliates. It sells its products through OEMs, distributors, and resellers; and online and retail stores. The company was founded in 1975 and is headquartered in Redmond, Washington.",
 'fullTimeEmployees': 228000,
 'companyOfficers': [{'maxAge': 1,
   'name': 'Mr. Satya  Nadella',
   'age': 57,
   'title': 'Chairman & CEO',
   'yearBorn': 1967,
   'fiscalYear': 2025,
   'totalPay': 12251294,
   'exercisedValue': 0,
   'unexercisedValue': 0},
  {'maxAge': 1,
 ...
```

```python
// ìµœê·¼ ì£¼ê°€ ì •ë³´ ë³´ê¸°
hist = msft.history(period="2mo") # 2ê°œì›”ê°„ì˜ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
display(hist) # ë°ì´í„° ì¶œë ¥
```
<img width="1204" height="821" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 02 07" src="https://github.com/user-attachments/assets/f55dd4f7-b284-45ad-b066-69260b07b695" />
<img width="1062" height="244" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 02 14" src="https://github.com/user-attachments/assets/cfb47817-bd10-400c-95fe-de05f2f045de" />


```python
// ì£¼ì‹ ì¢…ëª©ì˜ ì¶”ì²œ ì—¬ë¶€ ë³´ê¸°
msft.recommendations # ì¶”ì²œ ì •ë³´ ì¶œë ¥
```

<img width="520" height="209" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 04 19" src="https://github.com/user-attachments/assets/81e3f03a-c23c-412e-99b8-dd6bc08460e8" />


- [ì‹¤ìŠµ] GPTì—ì„œ ì‚¬ìš©í•  yfinance ê´€ë ¨ í•¨ìˆ˜ ë§Œë“¤ê¸°
    
    ```python
    from datetime import datetime
    import pytz
    import yfinance as yf
    
    def get_current_time(timezone: str = 'Asia/Seoul'):
        tz = pytz.timezone(timezone) # íƒ€ì„ì¡´ ì„¤ì •
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        now_timezone = f'{now} {timezone}'
        print(now_timezone)
        return now_timezone
    
    def get_yf_stock_info(ticker: str):
        stock = yf.Ticker(ticker)
        info = stock.info
        print(info)
        return str(info)
    
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_current_time",
                "description": "í•´ë‹¹ íƒ€ì„ì¡´ì˜ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'timezone': {
                            'type': 'string',
                            'description': 'í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•  íƒ€ì„ì¡´ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: Asia/Seoul)',
                        },
                    },
                    "required": ['timezone'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_info",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                    },
                    "required": ['ticker'],
                },        
            }
        }
    ]
    
    if __name__ == '__main__':
        # get_current_time('America/New_York')
        info = get_yf_stock_info('GOOGL')    
    ```
    
    ```python
    // êµ¬ê¸€ ì •ë³´ ì¶œë ¥ 
    {'address1': '1600 Amphitheatre Parkway', 'city': 'Mountain View', 'state': 'CA', 'zip': '94043', 'country': 'United States', 'phone': '650-253-0000', 'website': 'https://abc.xyz', 'industry': 'Internet Content & Information', 'industryKey': 'internet-content-information', 'industryDisp': 'Internet Content & Information', 'sector': 'Communication Services', 'sectorKey': 'communication-services', 'sectorDisp': 'Communication Services', 'longBusinessSummary': 'Alphabet Inc. offers various products and platforms in the United States, Europe, the Middle East, Africa, the Asia-Pacific, Canada, and Latin America. It operates through Google Services, Google Cloud, and Other Bets segments. The Google Services segment provides products and services, including ads, Android, Chrome, devices, Gmail, Google Drive, Google Maps, Google Photos, Google Play, Search, and YouTube. It is also involved in the sale of apps and in-app purchases and digital content in the Google Play and YouTube; and devices, as well as in the provision of YouTube consumer subscription services. The Google Cloud segment offers A
    ```
    
    ```
    from datetime import datetime
    import pytz
    import yfinance as yf
    
    def get_current_time(timezone: str = 'Asia/Seoul'):
        tz = pytz.timezone(timezone) # íƒ€ì„ì¡´ ì„¤ì •
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        now_timezone = f'{now} {timezone}'
        print(now_timezone)
        return now_timezone
    
    def get_yf_stock_info(ticker: str):
        stock = yf.Ticker(ticker)
        info = stock.info
        print(info)
        return str(info)
    
    def get_yf_stock_history(ticker: str, period: str):
        stock = yf.Ticker(ticker)
        history = stock.history(period=period)
        history_md = history.to_markdown() # ë°ì´í„°í”„ë ˆì„ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        print(history_md)
        return history_md
    
    def get_yf_stock_recommendations(ticker: str):
        stock = yf.Ticker(ticker)
        recommendations = stock.recommendations
        recommendations_md = recommendations.to_markdown() # ë°ì´í„°í”„ë ˆì„ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        print(recommendations_md)
        return recommendations_md
    
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_current_time",
                "description": "í•´ë‹¹ íƒ€ì„ì¡´ì˜ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'timezone': {
                            'type': 'string',
                            'description': 'í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•  íƒ€ì„ì¡´ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: Asia/Seoul)',
                        },
                    },
                    "required": ['timezone'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_info",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                    },
                    "required": ['ticker'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_history",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì£¼ê°€ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì£¼ê°€ ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                        'period': {
                            'type': 'string',
                            'description': 'ì£¼ê°€ ì •ë³´ë¥¼ ì¡°íšŒí•  ê¸°ê°„ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: 1d, 5d, 1mo, 1y, 5y)',
                        },
                    },
                    "required": ['ticker', 'period'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_recommendations",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì¶”ì²œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì¶”ì²œ ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                    },
                    "required": ['ticker'],
                },        
            }
        },
    ]
    
    if __name__ == '__main__':
        # get_current_time('America/New_York')
        # info = get_yf_stock_info('AAPL')  
    
        get_yf_stock_history('AAPL', '5d')
        print('----')
        get_yf_stock_recommendations('AAPL')
      
    ```
    
    ```python
    // ìŠ¤íŠ¸ë¦¼ë¦¿ ì‹¤í–‰
    from gpt_functions import get_current_time, tools, get_yf_stock_info
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    
    client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    def get_ai_response(messages, tools=None):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
        )
        return response  # ìƒì„±ëœ ì‘ë‹µ ë‚´ìš© ë°˜í™˜
    
    st.title("ğŸ’¬ Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        ai_message = ai_response.choices[0].message
        print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  # ë§Œì•½ tool_nameì´ "get_current_time"ì´ë¼ë©´
                    st.session_state.messages.append({
                        "role": "function",  # roleì„ "function"ìœ¼ë¡œ ì„¤ì •
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "content": get_current_time(timezone=arguments['timezone']),  # íƒ€ì„ì¡´ ì¶”ê°€
                    })
                elif tool_name == "get_yf_stock_info":
                    st.session_state.messages.append({
                        "role": "function",
                        "tool_call_id": tool_call_id,
                        "name": tool_name,
                        "content": get_yf_stock_info(ticker=arguments['ticker']),
                    })
    
            st.session_state.messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": ai_message.content
        })  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
        st.chat_message("assistant").write(ai_message.content)  # ë¸Œë¼ìš°ì €ì— ë©”ì‹œì§€ ì¶œë ¥
    ```
    <img width="827" height="771" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 22 23" src="https://github.com/user-attachments/assets/30045457-8cc2-4987-8144-d2488d7ac5ac" />

- [ì‹¤ìŠµ] ì½”ë“œ ë¦¬íŒ©í† ë§í•˜ê¸°
    
    ```python
    from gpt_functions import get_current_time, tools, get_yf_stock_info
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    
    client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    def get_ai_response(messages, tools=None):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
        )
        return response  # ìƒì„±ëœ ì‘ë‹µ ë‚´ìš© ë°˜í™˜
    
    st.title("ğŸ’¬ Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  #ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        ai_message = ai_response.choices[0].message
        print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  
                    func_result = get_current_time(timezone=arguments['timezone'])
                elif tool_name == "get_yf_stock_info":
                    func_result = get_yf_stock_info(ticker=arguments['ticker'])
           
                st.session_state.messages.append({
                    "role": "function",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": func_result,
                })
    
            st.session_state.messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": ai_message.content
        })  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
        st.chat_message("assistant").write(ai_message.content)  # ë¸Œë¼ìš°ì €ì— ë©”ì‹œì§€ ì¶œë ¥
    ```
    
- [ì‹¤ìŠµ] ì¢…ëª© ìµœê·¼ ì£¼ê°€ ì •ë³´ì™€ ì¶”ì²œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    
    ```
    from datetime import datetime
    import pytz
    import yfinance as yf
    
    def get_current_time(timezone: str = 'Asia/Seoul'):
        tz = pytz.timezone(timezone) # íƒ€ì„ì¡´ ì„¤ì •
        now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
        now_timezone = f'{now} {timezone}'
        print(now_timezone)
        return now_timezone
    
    def get_yf_stock_info(ticker: str):
        stock = yf.Ticker(ticker)
        info = stock.info
        print(info)
        return str(info)
    
    def get_yf_stock_history(ticker: str, period: str):
        stock = yf.Ticker(ticker)
        history = stock.history(period=period)
        history_md = history.to_markdown() # ë°ì´í„°í”„ë ˆì„ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        print(history_md)
        return history_md
    
    def get_yf_stock_recommendations(ticker: str):
        stock = yf.Ticker(ticker)
        recommendations = stock.recommendations
        recommendations_md = recommendations.to_markdown() # ë°ì´í„°í”„ë ˆì„ì„ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        print(recommendations_md)
        return recommendations_md
    
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_current_time",
                "description": "í•´ë‹¹ íƒ€ì„ì¡´ì˜ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'timezone': {
                            'type': 'string',
                            'description': 'í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ë°˜í™˜í•  íƒ€ì„ì¡´ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: Asia/Seoul)',
                        },
                    },
                    "required": ['timezone'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_info",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                    },
                    "required": ['ticker'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_history",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì£¼ê°€ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì£¼ê°€ ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                        'period': {
                            'type': 'string',
                            'description': 'ì£¼ê°€ ì •ë³´ë¥¼ ì¡°íšŒí•  ê¸°ê°„ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: 1d, 5d, 1mo, 1y, 5y)',
                        },
                    },
                    "required": ['ticker', 'period'],
                },        
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_yf_stock_recommendations",
                "description": "í•´ë‹¹ ì¢…ëª©ì˜ Yahoo Finance ì¶”ì²œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        'ticker': {
                            'type': 'string',
                            'description': 'Yahoo Finance ì¶”ì²œ ì •ë³´ë¥¼ ë°˜í™˜í•  ì¢…ëª©ì˜ í‹°ì»¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: AAPL)',
                        },
                    },
                    "required": ['ticker'],
                },        
            }
        },
    ]
    
    if __name__ == '__main__':
        # get_current_time('America/New_York')
        # info = get_yf_stock_info('AAPL')  
    
        get_yf_stock_history('AAPL', '5d')
        print('----')
        get_yf_stock_recommendations('AAPL')
      
    ```
    
    | Date | Open | High | Low | Close | Volume | Dividends | Stock Splits |
    | --- | --- | --- | --- | --- | --- | --- | --- |
    | 2025-11-10 00:00:00-05:00 | 268.96 | 273.73 | 267.46 | 269.43 | 4.13124e+07 | 0.26 | 0 |
    | 2025-11-11 00:00:00-05:00 | 269.81 | 275.91 | 269.8 | 275.25 | 4.62083e+07 | 0 | 0 |
    | 2025-11-12 00:00:00-05:00 | 275 | 275.73 | 271.7 | 273.47 | 4.8398e+07 | 0 | 0 |
    | 2025-11-13 00:00:00-05:00 | 274.11 | 276.7 | 272.09 | 272.95 | 4.96028e+07 | 0 | 0 |
    | 2025-11-14 00:00:00-05:00 | 271.05 | 275.96 | 269.6 | 272.41 | 4.73993e+07 | 0 | 0 |
    
    ---
    
    |  | period | strongBuy | buy | hold | sell | strongSell |
    | --- | --- | --- | --- | --- | --- | --- |
    | 0 | 0m | 5 | 24 | 15 | 1 | 3 |
    | 1 | -1m | 5 | 24 | 15 | 1 | 3 |
    | 2 | -2m | 5 | 23 | 15 | 1 | 3 |
    | 3 | -3m | 5 | 22 | 15 | 1 | 1 |
    
    ```python
    from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")  
    
    client = OpenAI(api_key=api_key) 
    
    def get_ai_response(messages, tools=None):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ ì§€ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ì „ë‹¬
        )
        return response  # ìƒì„±ëœ ì‘ë‹µ ë‚´ìš© ë°˜í™˜
    
    st.title("ğŸ’¬ Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        ai_message = ai_response.choices[0].message
        print(ai_message)  # gptì—ì„œ ë°˜í™˜ë˜ëŠ” ê°’ì„ íŒŒì•…í•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¶”ê°€
    
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  
                    func_result = get_current_time(timezone=arguments['timezone'])
                elif tool_name == "get_yf_stock_info":
                    func_result = get_yf_stock_info(ticker=arguments['ticker'])
                elif tool_name == "get_yf_stock_history":  # get_yf_stock_history í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_history(
                        ticker=arguments['ticker'], 
                        period=arguments['period']
                    )
                elif tool_name == "get_yf_stock_recommendations":  # get_yf_stock_recommendations í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_recommendations(
                        ticker=arguments['ticker']
                    )
    
                st.session_state.messages.append({
                    "role": "function",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": func_result,
                })
    
            st.session_state.messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": ai_message.content
        })  #AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
        st.chat_message("assistant").write(ai_message.content)  # ë¸Œë¼ìš°ì €ì— ë©”ì‹œì§€ ì¶œë ¥
    ```
    
  <img width="760" height="648" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 35 22" src="https://github.com/user-attachments/assets/bf4a3ff5-1973-47f7-adc5-269baf4fcf34" />

    

07-3 ìŠ¤íŠ¸ë¦¼ ì¶œë ¥í•˜ê¸°

- [ì‹¤ìŠµ] í„°ë¯¸ë„ ì°½ì—ì„œ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ê¸°
    
    ```python
    from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    
    client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    def get_ai_response(messages, tools=None, stream=True):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
            stream=stream, # (1) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•´ ì„¤ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
        )
    
        if stream: 
            for chunk in response:
                yield chunk  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ yieldë¡œ ìˆœì°¨ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        else:
            return response  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    st.title("ğŸ’¬ Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        # print(ai_message) 
    
        content = ''
        for chunk in ai_response:
            content_chunk = chunk.choices[0].delta.content # ì²­í¬ ì† content ì¶”ì¶œ
            if content_chunk: # ë§Œì•½ content_chunkê°€ ìˆë‹¤ë©´, 
                print(content_chunk, end="")	 # í„°ë¯¸ë„ì— ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥
                content += content_chunk # contentì— ë§ë¶™ì´ê¸°
            
        print('\n===========')
        print(content)
    
        ai_message = ai_response.choices[0].message
        tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  
                    func_result = get_current_time(timezone=arguments['timezone'])
                elif tool_name == "get_yf_stock_info":
                    func_result = get_yf_stock_info(ticker=arguments['ticker'])
                elif tool_name == "get_yf_stock_history":  # get_yf_stock_history í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_history(
                        ticker=arguments['ticker'], 
                        period=arguments['period']
                    )
                elif tool_name == "get_yf_stock_recommendations":  # get_yf_stock_recommendations í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_recommendations(
                        ticker=arguments['ticker']
                    )
    
                st.session_state.messages.append({
                    "role": "function",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": func_result,
                })
    
            st.session_state.messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": ai_message.content
        })  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + ai_message.content)  # AI ì‘ë‹µ ì¶œë ¥
        st.chat_message("assistant").write(ai_message.content)  # ë¸Œë¼ìš°ì €ì— ë©”ì‹œì§€ ì¶œë ¥
    ```
    
- [ì‹¤ìŠµ] ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ê¸°
    
    ```
    from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    
    client = OpenAI(api_key=api_key)  # ì˜¤í”ˆAI í´ë¼ì´ì–¸íŠ¸ì˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    
    def get_ai_response(messages, tools=None, stream=True):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
            stream=stream, # (1) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•´ ì„¤ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
        )
    
        if stream: 
            for chunk in response:
                yield chunk  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ yieldë¡œ ìˆœì°¨ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        else:
            return response  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    st.title("ğŸ’¬ Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        # print(ai_message) 
    
        content = ''
        tool_calls = None # # tool_calls ì´ˆê¸°í™”
        
        with st.chat_message("assistant").empty(): # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±— ë©”ì‹œì§€ ì´ˆê¸°í™”
            for chunk in ai_response:
                content_chunk = chunk.choices[0].delta.content # ì²­í¬ ì† content ì¶”ì¶œ
                if content_chunk: # ë§Œì•½ content_chunkê°€ ìˆë‹¤ë©´, 
                    print(content_chunk, end="")	 # í„°ë¯¸ë„ì— ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥
                    content += content_chunk # contentì— ë§ë¶™ì´ê¸°
                    st.markdown(content) # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±— ë©”ì‹œì§€ì— ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥
            
        print('\n===========')
        print(content)
    
        # ai_message = ai_response.choices[0].message
        # tool_calls = ai_message.tool_calls  # AI ì‘ë‹µì— í¬í•¨ëœ tool_callsë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  
                    func_result = get_current_time(timezone=arguments['timezone'])
                elif tool_name == "get_yf_stock_info":
                    func_result = get_yf_stock_info(ticker=arguments['ticker'])
                elif tool_name == "get_yf_stock_history":  # get_yf_stock_history í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_history(
                        ticker=arguments['ticker'], 
                        period=arguments['period']
                    )
                elif tool_name == "get_yf_stock_recommendations":  # get_yf_stock_recommendations í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_recommendations(
                        ticker=arguments['ticker']
                    )
    
                st.session_state.messages.append({
                    "role": "function",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": func_result,
                })
    
            st.session_state.messages.append({"role": "system", "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."}) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            ai_message = ai_response.choices[0].message
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": content # ì›ë˜ëŠ” ai_message.content ì˜€ìŒ
        })  # â‘¢ AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + content)  # AI ì‘ë‹µ ì¶œë ¥
        # st.chat_message("assistant").write(content)  # ìœ„ì—ì„œ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì¶œë ¥í•˜ë¯€ë¡œ ë¶ˆí•„ìš”
    ```
    <img width="545" height="842" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 50 38" src="https://github.com/user-attachments/assets/eefa43dd-48d4-4a6c-b09c-49f612372dcd" />

- [ì‹¤ìŠµ] ìŠ¤íŠ¸ë¦¼ ë°©ì‹ì—ì„œ í‘ì…˜ ì½œë§ ì‚¬ìš©í•˜ê¸°
    
    ```python
    from gpt_functions import get_current_time, tools, get_yf_stock_info, get_yf_stock_history, get_yf_stock_recommendations
    from openai import OpenAI
    from dotenv import load_dotenv
    import os
    import json
    import streamlit as st
    from collections import defaultdict
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    client = OpenAI(api_key=api_key)  
    
    def tool_list_to_tool_obj(tools):
        # ê¸°ë³¸ ê°’ì„ ê°€ì§„ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
        tool_calls_dict = defaultdict(lambda: {"id": None, "function": {"arguments": "", "name": None}, "type": None})
    
        # ë„êµ¬(í•¨ìˆ˜) í˜¸ì¶œì„ ë°˜ë³µí•˜ì—¬ ì²˜ë¦¬
        for tool_call in tools:
            # idê°€ Noneì´ ì•„ë‹Œ ê²½ìš° ì„¤ì •
            if tool_call.id is not None:
                tool_calls_dict[tool_call.index]["id"] = tool_call.id
    
            # í•¨ìˆ˜ ì´ë¦„ì´ Noneì´ ì•„ë‹Œ ê²½ìš° ì„¤ì •
            if tool_call.function.name is not None:
                tool_calls_dict[tool_call.index]["function"]["name"] = tool_call.function.name
    
            # ì¸ìˆ˜ ì¶”ê°€
            tool_calls_dict[tool_call.index]["function"]["arguments"] += tool_call.function.arguments
    
            # íƒ€ì…ì´ Noneì´ ì•„ë‹Œ ê²½ìš° ì„¤ì •
            if tool_call.type is not None:
                tool_calls_dict[tool_call.index]["type"] = tool_call.type
    
        # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        tool_calls_list = list(tool_calls_dict.values())
    
        return {"tool_calls": tool_calls_list}  
    
    def get_ai_response(messages, tools=None, stream=True):
        response = client.chat.completions.create(
            model="gpt-4o",  # ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤.
            stream=stream, # (1) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•´ ì„¤ì •
            messages=messages,  # ëŒ€í™” ê¸°ë¡ì„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
            tools=tools,  # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ì „ë‹¬í•©ë‹ˆë‹¤.
        )
    
        if stream: 
            for chunk in response:
                yield chunk  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ yieldë¡œ ìˆœì°¨ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        else:
            return response  # ìƒì„±ëœ ì‘ë‹µì˜ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    st.title("ğŸ’¬ Chatbot")   
    
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "system", "content": "ë„ˆëŠ” ì‚¬ìš©ìë¥¼ ë„ì™€ì£¼ëŠ” ìƒë‹´ì‚¬ì•¼."},  # ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€
        ] 
    
    for msg in st.session_state.messages:
        if msg["role"] == "assistant" or msg["role"] == "user": # assistant í˜¹ì€ user ë©”ì‹œì§€ì¸ ê²½ìš°ë§Œ
            st.chat_message(msg["role"]).write(msg["content"])
    
    if user_input := st.chat_input():    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        st.session_state.messages.append({"role": "user", "content": user_input})  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.chat_message("user").write(user_input)  # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¸Œë¼ìš°ì €ì—ì„œë„ ì¶œë ¥
        
        ai_response = get_ai_response(st.session_state.messages, tools=tools)
        # print(ai_message) 
    
        content = ''
        tool_calls = None # # tool_calls ì´ˆê¸°í™”
        tool_calls_chunk = []   # tool_calls_chunk ì´ˆê¸°í™”
        
        with st.chat_message("assistant").empty(): # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±— ë©”ì‹œì§€ ì´ˆê¸°í™”
            for chunk in ai_response:
                content_chunk = chunk.choices[0].delta.content # ì²­í¬ ì† content ì¶”ì¶œ
                if content_chunk: # ë§Œì•½ content_chunkê°€ ìˆë‹¤ë©´, 
                    print(content_chunk, end="")	 # í„°ë¯¸ë„ì— ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ì„œ ì¶œë ¥
                    content += content_chunk # contentì— ë§ë¶™ì´ê¸°
                    st.markdown(content) # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±— ë©”ì‹œì§€ì— ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥
                
                # print(chunk) # ì„ì‹œë¡œ ì²­í¬ ì¶œë ¥
                if chunk.choices[0].delta.tool_calls:	# tool_callsê°€ ìˆëŠ” ê²½ìš°
                    tool_calls_chunk += chunk.choices[0].delta.tool_calls # tool_calls_chunkì— ì¶”ê°€
    
        tool_obj = tool_list_to_tool_obj(tool_calls_chunk)
        tool_calls = tool_obj["tool_calls"]   
    
        if len(tool_calls) > 0: # ë§Œì•½ tool_callsê°€ ì¡´ì¬í•˜ë©´, st.writeë¡œ tool_call ë‚´ìš© ì¶œë ¥
            print(tool_calls)
            # tool_callsì—ì„œ function ì •ë³´ë§Œ ëª¨ì•„ì„œ ì¶œë ¥
            tool_call_msg = [tool_call["function"] for tool_call in tool_calls]
            st.write(tool_call_msg) 
    
        print('\n===========')
        print(content)
    
        # print('\n=========== tool_calls_chunk')  # tool_calls_chunk í™•ì¸í•˜ê¸° ìœ„í•œ ì½”ë“œ
        # for tool_call_chunk in tool_calls_chunk:
        #     print(tool_call_chunk)
    
        # tool_obj = tool_list_to_tool_obj(tool_calls_chunk) # ìœ„ë¡œ ì´ë™
        # tool_calls = tool_obj["tool_calls"] # ìœ„ë¡œ ì´ë™ë™
        print(tool_calls)
    
        if tool_calls:  # tool_callsê°€ ìˆëŠ” ê²½ìš°
            for tool_call in tool_calls:
                # tool_name = tool_call.function.name # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                # tool_call_id = tool_call.id         # tool_call ì•„ì´ë”” ë°›ê¸°    
                # arguments = json.loads(tool_call.function.arguments) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
    
                # ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—ì„œ ë°›ê¸°
                tool_name = tool_call["function"]["name"]  # ì‹¤í–‰í•´ì•¼í•œë‹¤ê³  íŒë‹¨í•œ í•¨ìˆ˜ëª… ë°›ê¸°
                tool_call_id = tool_call["id"]         # í•¨ìˆ˜ ì•„ì´ë”” ë°›ê¸°
                arguments = json.loads(tool_call["function"]["arguments"]) # ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜    
                
                if tool_name == "get_current_time":  
                    func_result = get_current_time(timezone=arguments['timezone'])
                elif tool_name == "get_yf_stock_info":
                    func_result = get_yf_stock_info(ticker=arguments['ticker'])
                elif tool_name == "get_yf_stock_history":  # get_yf_stock_history í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_history(
                        ticker=arguments['ticker'], 
                        period=arguments['period']
                    )
                elif tool_name == "get_yf_stock_recommendations":  # get_yf_stock_recommendations í•¨ìˆ˜ í˜¸ì¶œ
                    func_result = get_yf_stock_recommendations(
                        ticker=arguments['ticker']
                    )
    
                st.session_state.messages.append({
                    "role": "function",
                    "tool_call_id": tool_call_id,
                    "name": tool_name,
                    "content": func_result,
                })
    
            st.session_state.messages.append({
                "role": "system", 
                "content": "ì´ì œ ì£¼ì–´ì§„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•  ì°¨ë¡€ë‹¤."
            }) 
            ai_response = get_ai_response(st.session_state.messages, tools=tools) # ë‹¤ì‹œ GPT ì‘ë‹µ ë°›ê¸°
            # ai_message = ai_response.choices[0].message
            content = ""
            with st.chat_message("assistant").empty():
                for chunk in ai_response:
                    content_chunk = chunk.choices[0].delta.content
                    if content_chunk:
                        print(content_chunk, end='')
                        content += content_chunk
                        st.markdown(content) # ìŠ¤íŠ¸ë¦¼ë¦¿ ì±—ë©”ì‹œì§€ì— markdownìœ¼ë¡œ ì¶œë ¥
    
        st.session_state.messages.append({
            "role": "assistant",
            "content": content # ì›ë˜ëŠ” ai_message.content ì˜€ìŒ
        })  # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    
        print("AI\t: " + content)  # AI ì‘ë‹µ ì¶œë ¥
        # st.chat_message("assistant").write(content)  # ìœ„ì—ì„œ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì¶œë ¥í•˜ë¯€ë¡œ ë¶ˆí•„ìš”
    ```
    <img width="775" height="777" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-11-16 á„‹á…©á„’á…® 5 57 37" src="https://github.com/user-attachments/assets/0cd430a5-b805-493c-8865-99aedc433e55" />

    
    
